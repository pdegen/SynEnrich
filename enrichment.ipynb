{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPItyn/aHfVlIKXYTYWZ/ID",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pdegen/SynEnrich/blob/main/enrichment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfA58UPWqWN_"
      },
      "outputs": [],
      "source": [
        "import os, sys, glob\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def npg_palette():\n",
        "    palette = [\"#E64B35FF\", \"#4DBBD5FF\", \"#00A087FF\", \"#3C5488FF\", \"#F39B7FFF\",\n",
        "               \"#8491B4FF\", \"#91D1C2FF\", \"#DC0000FF\", \"#7E6148FF\", \"#B09C85FF\"]\n",
        "    return sns.color_palette(palette, len(palette))\n",
        "\n",
        "npg = npg_palette()\n",
        "sns.set_style(\"whitegrid\", {'axes.linewidth': 2, 'axes.edgecolor':'black'})\n",
        "\n",
        "%load_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare"
      ],
      "metadata": {
        "id": "y5an1WRWrVCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/drive/MyDrive/rnaseq_chiara\"\n",
        "\n",
        "paramset = \"p1\" # Kallisto\n",
        "\n",
        "csvpath = PATH + f\"/CSV/{paramset}\"\n",
        "plotpath = PATH + f\"/Figures/{paramset}\"\n",
        "\n",
        "contrasts = [\"KO_WT\",\"SA_WT\",\"SD_WT\",\"SD_SA\",\"KO_SD\",\"KO_SA\"]\n",
        "\n",
        "gene_dict_path = f\"{csvpath}/gene_dict.{paramset}.csv\"\n",
        "\n",
        "fdr_cutoff = 0.05 # cutoff for ClusterProfiler"
      ],
      "metadata": {
        "id": "OT7kixHCqlBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = \"qlf\"\n",
        "lfc = 0\n",
        "\n",
        "for c in contrasts:\n",
        "  outfile = f\"{csvpath}/DEGs/edger.{test}.lfc{lfc}.{c}.{paramset}.csv\"\n",
        "  tab = pd.read_csv(outfile, index_col=0).sort_values(by=\"logFC\")\n",
        "\n",
        "  #tab[\"logFC\"].to_csv(f\"{csvpath}/Enrichment/gsea_lfc.{c}.edger.{test}.{paramset}.csv\", header=False)\n",
        "\n",
        "  tab[\"signed_logpval\"] = -np.sign(tab[\"logFC\"]) * np.log10(tab[\"PValue\"])\n",
        "  #tab[\"signed_logpval\"].to_csv(f\"{csvpath}/Enrichment/gsea_signed_logpval.{c}.edger.{test}.{paramset}.csv\", header=False)\n",
        "\n",
        "  #tab[\"signed_logpvaladj\"] = -np.sign(tab[\"logFC\"]) * np.log10(tab[\"FDR\"])\n",
        "  #tab[\"signed_logpvaladj\"].to_csv(f\"{csvpath}/Enrichment/gsea_signed_logpvaladj.{c}.edger.{test}.{paramset}.csv\", header=False)"
      ],
      "metadata": {
        "id": "LlWoIQGczIR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = f\"{csvpath}/Enrichment/gsea_{metric}.{c}.edger.qlf.{paramset}.csv\"\n",
        "tab = pd.read_csv(f, index_col=0, header=None)\n",
        "\n",
        "tab.index = tab.index.map(gene_dict['gene_name'].to_dict())\n",
        "tab = tab.reset_index().dropna()\n",
        "tab = tab.set_index(0)\n",
        "\n",
        "print(len(tab))\n",
        "tab = tab.loc[~tab.index.duplicated()]\n",
        "tab = tab.sort_values(by=1,ascending=False)\n",
        "tab"
      ],
      "metadata": {
        "id": "B8WFc3N8HcMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STRING\n",
        "\n",
        "\n",
        "ALthough STRING provides an [API](https://string-db.org/cgi/help?sessionId=bP1AEa0XqxI7&subpage=api), I couldn't find a method to perform functional scoring analysis (only over-representation analysis). Hence, you must use the web interface instead: [Proteins with Values/Ranks - Functional Enrichment Analysis](https://string-db.org/cgi/input?sessionId=blqQmZLHEd5T&input_page_active_form=proteins_with_values)"
      ],
      "metadata": {
        "id": "wttwqkqKMczH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ClusterProfiler\n",
        "\n",
        "Gene list must be in [decreasing order](https://yulab-smu.top/biomedical-knowledge-mining-book/faq.html#genelist)"
      ],
      "metadata": {
        "id": "H-Vr67QtqqUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "rpath = \"/content/drive/MyDrive/single-nuclei/RPackages/\"\n",
        ".libPaths(rpath)\n",
        "\n",
        "# start_time <- Sys.time()\n",
        "\n",
        "#install.packages(\"ggsci\", lib = rpath)\n",
        "\n",
        "# if (!require(\"BiocManager\", quietly = TRUE))\n",
        "#     install.packages(\"BiocManager\", lib = rpath)\n",
        "\n",
        "#library(BiocManager, lib.loc = rpath)\n",
        "#BiocManager:lib = rpath:install(\"clusterProfiler\", lib = rpath)\n",
        "#BiocManager::install(\"org.Hs.eg.db\", lib=rpath)\n",
        "#BiocManager::install(\"biomaRt\", lib=rpath)\n",
        "\n",
        "# end_time <- Sys.time()\n",
        "# print(end_time - start_time)"
      ],
      "metadata": {
        "id": "MeqQXViUqrle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R -i gene_dict_path\n",
        "\n",
        "gene_dict = read.csv(gene_dict_path)\n",
        "head(gene_dict)\n",
        "library(org.Hs.eg.db)\n",
        "keytypes(org.Hs.eg.db)"
      ],
      "metadata": {
        "id": "5tzHZO14rD9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "if (!(\"entrezgene_id\" %in% colnames(gene_dict))) {\n",
        "  print(\"Appending entrez IDs...\")\n",
        "  library(biomaRt)\n",
        "  ensembl <- useMart(\"ensembl\", dataset = \"hsapiens_gene_ensembl\")\n",
        "\n",
        "  ensg_ids <- gene_dict$gene_id\n",
        "\n",
        "  gene_info <- getBM(attributes = c('ensembl_gene_id', 'entrezgene_id'),\n",
        "                    filters = 'ensembl_gene_id',\n",
        "                    values = ensg_ids,\n",
        "                    mart = ensembl)\n",
        "\n",
        "  gene_dict <- merge(gene_dict, gene_info, by.x = \"gene_id\", by.y = \"ensembl_gene_id\", all.x = TRUE)\n",
        "  write.csv(gene_dict,gene_dict_path, row.names = FALSE)\n",
        "}"
      ],
      "metadata": {
        "id": "_TCRDfStrhQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R -i csvpath,paramset,contrasts,fdr_cutoff\n",
        "\n",
        "library(clusterProfiler, lib=rpath)\n",
        "\n",
        "organism <- \"org.Hs.eg.db\"\n",
        "organism_kegg <- \"hsa\"\n",
        "\n",
        "#metric <- \"lfc\"\n",
        "metric <- \"signed_logpval\"\n",
        "#metric <- \"signed_logpvaladj\"\n",
        "\n",
        "overwrite = FALSE\n",
        "\n",
        "for (c in contrasts) {\n",
        "\n",
        "  outfile <- paste0(csvpath,\"/Enrichment/clusterprofiler/cluster.gseGO.\",metric,\".\",c,\".\",paramset,\".csv\")\n",
        "  outfile_kegg <- paste0(csvpath,\"/Enrichment/clusterprofiler/cluster.gseKEGG.\",metric,\".\",c,\".\",paramset,\".csv\")\n",
        "\n",
        "  if (file.exists(outfile) && file.exists(outfile_kegg) && !overwrite) {\n",
        "    print(\"Existing files not overwritte, skipping\")\n",
        "    next\n",
        "  }\n",
        "\n",
        "  start_time <- Sys.time()\n",
        "  p <- paste0(csvpath,\"/Enrichment/gsea_\",metric,\".\",c,\".edger.qlf.\",paramset,\".csv\")\n",
        "  print(p)\n",
        "\n",
        "  d = read.csv(p, header=FALSE, col.names=c(\"gene_id\", \"metric\"))\n",
        "  print(paste(\"ENSMBL genes:\", nrow(d)))\n",
        "\n",
        "  # Convert to ENTREZ ID\n",
        "  # We will lose some genes here because not all IDs will be converted\n",
        "  ids<-bitr(d$gene_id, fromType = \"ENSEMBL\", toType = \"ENTREZID\", OrgDb=organism)\n",
        "  dedup_ids = ids[!duplicated(ids[c(\"ENSEMBL\")]),]\n",
        "  df2 = d[d$gene_id %in% dedup_ids$ENSEMBL,]\n",
        "  df2$Y = dedup_ids$ENTREZID\n",
        "\n",
        "  #d <- d[order(d$metric, decreasing = TRUE), ]\n",
        "  #print(head(d))\n",
        "\n",
        "  geneList <- df2$metric\n",
        "  names(geneList) <- df2$Y\n",
        "  geneList<-na.omit(geneList)\n",
        "  geneList = sort(geneList, decreasing = TRUE)\n",
        "\n",
        "  #print(head(geneList))\n",
        "  print(paste(\"ENTREZ genes:\", length(geneList)))\n",
        "\n",
        "  if (!file.exists(outfile) || overwrite) {\n",
        "\n",
        "    ego3 <- gseGO(geneList     = geneList,\n",
        "                  OrgDb        = organism,\n",
        "                  ont          = \"ALL\", ## CC MF BP\n",
        "                  minGSSize    = 100,\n",
        "                  maxGSSize    = 500,\n",
        "                  pvalueCutoff = fdr_cutoff,\n",
        "                  nPerm = 1000,\n",
        "                  verbose      = FALSE)\n",
        "    write.csv(ego3,outfile)\n",
        "  }\n",
        "\n",
        "  if (!file.exists(outfile_kegg) || overwrite) {\n",
        "\n",
        "    kegg <- gseKEGG(geneList     = geneList,\n",
        "                  organism        = organism_kegg,\n",
        "                  minGSSize    = 100,\n",
        "                  maxGSSize    = 500,\n",
        "                  pvalueCutoff = fdr_cutoff,\n",
        "                  nPerm = 1000,\n",
        "                  verbose      = FALSE)\n",
        "    write.csv(kegg,outfile_kegg)\n",
        "  }\n",
        "\n",
        "  end_time <- Sys.time()\n",
        "  print(end_time - start_time)\n",
        "}"
      ],
      "metadata": {
        "id": "JWlyulekrppA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GSEApy\n",
        "\n",
        "Note: GSEApy ranks in ascending=False order (as of commit 275972e)\n",
        "\n",
        "https://github.com/zqfang/GSEApy/blob/master/gseapy/gsea.py#L356\n",
        "\n",
        "https://github.com/zqfang/GSEApy/blob/master/gseapy/gsea.py#L398"
      ],
      "metadata": {
        "id": "25XDuKPBHDSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import gseapy\n",
        "except ModuleNotFoundError:\n",
        "  !pip install gseapy\n",
        "  import gseapy"
      ],
      "metadata": {
        "id": "PvXvVtpoHDXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gene_dict = pd.read_csv(gene_dict_path, index_col=0)\n",
        "print(len(gene_dict))\n",
        "gene_dict.head()"
      ],
      "metadata": {
        "id": "MC4qY-gCPpn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ontologies = [\"GO_Biological_Process_2023\",\"GO_Cellular_Component_2023\",\n",
        "              \"GO_Molecular_Function_2023\",\"KEGG_2021_Human\"]\n",
        "\n",
        "def run_gseapy_multi(contrasts, metric, overwrite=False, **kwargs):\n",
        "\n",
        "  if isinstance(contrasts, str):\n",
        "    contrasts = [contrasts]\n",
        "\n",
        "  for c in contrasts:\n",
        "    print(c)\n",
        "\n",
        "    outfile = f\"{csvpath}/Enrichment/gseapy.{metric}.{c}.{paramset}.csv\"\n",
        "\n",
        "    if os.path.isfile(outfile) and not overwrite:\n",
        "      print(f\"Existing file not overwritten: {outfile}\")\n",
        "      continue\n",
        "    else:\n",
        "      print(f\"Running GSEApy\")\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    f = f\"{csvpath}/Enrichment/gsea_{metric}.{c}.edger.qlf.{paramset}.csv\"\n",
        "    tab = pd.read_csv(f, index_col=0, header=None)\n",
        "\n",
        "    tab.index = tab.index.map(gene_dict['gene_name'].to_dict())\n",
        "    tab = tab.reset_index().dropna()\n",
        "    tab = tab.set_index(0)\n",
        "\n",
        "    print(len(tab))\n",
        "    tab = tab.loc[~tab.index.duplicated()]\n",
        "    print(len(tab))\n",
        "\n",
        "    res_list = []\n",
        "    for ont in ontologies:\n",
        "      res = run_gseapy(tab, ont, **kwargs)\n",
        "      res_list.append(res.res2d)\n",
        "\n",
        "    res_merged = pd.concat(res_list)\n",
        "    res_merged = res_merged.reset_index(drop=True)\n",
        "\n",
        "    res_merged.to_csv(outfile)\n",
        "\n",
        "    end = time.time()\n",
        "    print(\"Time difference:\", end - start)\n",
        "\n",
        "def run_gseapy(tab, ontology, outdir=None, **kwargs):\n",
        "    res = gseapy.prerank(rnk=tab, gene_sets=ontology, outdir=None, **kwargs)\n",
        "    res.res2d[\"Ontology\"] = ontology\n",
        "    return res"
      ],
      "metadata": {
        "id": "pkUcme6DHMcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#metric = \"signed_logpval\"\n",
        "run_gseapy_multi(contrasts, metric, overwrite=False)"
      ],
      "metadata": {
        "id": "bh_7QSvuOqz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outfile = f\"{csvpath}/Enrichment/gseapy.{metric}.KO_WT.{paramset}.csv\"\n",
        "tab=pd.read_csv(outfile,index_col=0)\n",
        "g=tab[tab[\"Ontology\"].str.startswith(\"GO_\")]\n",
        "g[g[\"FDR q-val\"]<0.05]"
      ],
      "metadata": {
        "id": "pctMtdO_XAbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method comparison"
      ],
      "metadata": {
        "id": "r5er6JJDC336"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import bioservices\n",
        "except ModuleNotFoundError:\n",
        "  !pip install bioservices\n",
        "  import bioservices"
      ],
      "metadata": {
        "id": "IDCbLGHnkpg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bioservices import KEGG\n",
        "\n",
        "pathway_terms = [\"Axon guidance\", \"Alanine, aspartate and glutamate metabolism\", \"Basal transcription factors\"]\n",
        "\n",
        "if \"kegg_ids_df\" not in globals():\n",
        "  try:\n",
        "    kegg_ids_df = pd.read_csv(f\"{csvpath}/kegg_ids_df.csv\", index_col=0)\n",
        "  except FileNotFoundError:\n",
        "    print(\"Creating kegg_ids_df.csv\")\n",
        "    kegg_ids_df = pd.DataFrame(columns=[\"Term\",\"ID\"])\n",
        "\n",
        "# Function to get KEGG pathway ID from term\n",
        "# Also returns boolean to indicate if kegg_ids_df df has been updated\n",
        "def get_kegg_id_hsa(term):\n",
        "\n",
        "  assert \"kegg_ids_df\" in globals(), \"kegg_ids_df not defined\"\n",
        "\n",
        "  if term in kegg_ids_df[\"Term\"].values:\n",
        "    return kegg_ids_df[kegg_ids_df[\"Term\"]==term][\"ID\"].values[0], False\n",
        "  else:\n",
        "    print(f\"Checking bioservices for term: {term}\")\n",
        "  k = KEGG()\n",
        "  try:\n",
        "      term = term.replace(\",\",\"\") # comma results in 400 bad request\n",
        "      term = term.replace(\"/\",\"\")\n",
        "\n",
        "      search_results = k.find(\"pathway\", term)\n",
        "      # Assuming the first result is the best match\n",
        "      first_result = search_results.split('\\n')[0]\n",
        "      kegg_id = first_result.split('\\t')[0]\n",
        "      kegg_id = kegg_id.replace(\"path:map\",\"hsa\")\n",
        "      kegg_ids_df.loc[len(kegg_ids_df)] = [term, kegg_id]\n",
        "      return kegg_id, True\n",
        "  except Exception as e:\n",
        "      print(f\"Error retrieving KEGG ID for term '{term}': {e}\")\n",
        "      return None\n",
        "\n",
        "# Get KEGG IDs for each term\n",
        "kegg_ids = {term: get_kegg_id_hsa(term)[0] for term in pathway_terms}\n",
        "print(kegg_ids)\n",
        "\n",
        "#get_kegg_id_hsa(pathway_terms[1])"
      ],
      "metadata": {
        "id": "61FDTbWmkvqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f = f\"{csvpath}/Enrichment/gseapy/gseapy.{metric}.{c}.{paramset}.csv\"\n",
        "# tab_gs = pd.read_csv(f, index_col=0)\n",
        "\n",
        "# tab_gs = tab_gs[tab_gs[\"FDR q-val\"]<fdr]\n",
        "# tab_gs = tab_gs[(tab_gs[\"Ontology\"].str.startswith(\"GO_\")) | (tab_gs[\"Ontology\"].str.startswith(\"KEGG_\"))]\n",
        "# go_ix = tab_gs[tab_gs[\"Ontology\"].str.startswith(\"GO_\")].index\n",
        "# tab_gs.loc[go_ix, \"ID\"] = \"GO:\" + tab_gs[\"Term\"].str.split(\"\\(GO:\").str[1].str[:-1]\n",
        "\n",
        "# tab_gs"
      ],
      "metadata": {
        "id": "ReHIAWvX-wow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib_venn import venn3, venn3_circles\n",
        "\n",
        "fdr = 0.01 # stringency used for method comparison\n",
        "metric = \"signed_logpval\"\n",
        "\n",
        "results_dict = {c: None for c in contrasts}\n",
        "\n",
        "for c in contrasts:\n",
        "\n",
        "  ############ STRING ############\n",
        "  f = f\"{csvpath}/Enrichment/string/{c}.{metric}.enrichment.all.{paramset}.tsv\"\n",
        "  tab = pd.read_csv(f, sep=\"\\t\")\n",
        "  tab = tab[(tab[\"#category\"].str.startswith(\"GO\")) | (tab[\"#category\"].str.startswith(\"KEGG\"))]\n",
        "  tab = tab[tab[\"false discovery rate\"]<fdr]\n",
        "  tab = tab.rename({\"term ID\":\"ID\"}, axis=1)\n",
        "\n",
        "  ############ CLUSTERPROFILER ############\n",
        "  f = f\"{csvpath}/Enrichment/clusterprofiler/cluster.gseGO.{metric}.{c}.{paramset}.csv\"\n",
        "  tab_cl = pd.read_csv(f, index_col=0)\n",
        "\n",
        "  f = f\"{csvpath}/Enrichment/clusterprofiler/cluster.gseKEGG.{metric}.{c}.{paramset}.csv\"\n",
        "  tab_cl_kegg = pd.read_csv(f, index_col=0)\n",
        "\n",
        "  tab_cl = pd.concat([tab_cl,tab_cl_kegg])\n",
        "  tab_cl = tab_cl[tab_cl[\"qvalue\"]<fdr]\n",
        "\n",
        "  ############ GSEAPY ############\n",
        "  f = f\"{csvpath}/Enrichment/gseapy/gseapy.{metric}.{c}.{paramset}.csv\"\n",
        "  tab_gs = pd.read_csv(f, index_col=0)\n",
        "\n",
        "  is_dirty = False\n",
        "  if \"ID\" not in tab_gs:\n",
        "    print(\"Retrieving KEGG IDs for GSEApy...\")\n",
        "    tab_gs[\"ID\"] = np.NaN\n",
        "    ix = tab_gs[tab_gs[\"Ontology\"].str.startswith(\"KEGG_\")].index\n",
        "    for k, i in enumerate(ix):\n",
        "      term = tab_gs.loc[i, \"Term\"]\n",
        "      tab_gs.loc[i,\"ID\"], new_kegg_id_found = get_kegg_id_hsa(term)\n",
        "      if new_kegg_id_found:\n",
        "        is_dirty = True\n",
        "      if k % 100 == 0: print(k,i,term)\n",
        "    tab_gs.to_csv(f)\n",
        "\n",
        "  tab_gs = tab_gs[tab_gs[\"FDR q-val\"]<fdr]\n",
        "  tab_gs = tab_gs[(tab_gs[\"Ontology\"].str.startswith(\"GO_\")) | (tab_gs[\"Ontology\"].str.startswith(\"KEGG_\"))]\n",
        "  go_ix = tab_gs[tab_gs[\"Ontology\"].str.startswith(\"GO_\")].index\n",
        "  tab_gs.loc[go_ix, \"ID\"] = \"GO:\" + tab_gs[\"Term\"].str.split(\"\\(GO:\").str[1].str[:-1]\n",
        "\n",
        "  if is_dirty:\n",
        "    print(\"Updating kegg_ids_df.csv\")\n",
        "    kegg_ids_df.to_csv(f\"{csvpath}/kegg_ids_df.csv\")\n",
        "\n",
        "  # JACCARD\n",
        "  # inter = set(tab[\"ID\"]).intersection(set(tab_cl[\"ID\"]))\n",
        "  # union = set(tab[\"ID\"]).union(set(tab_cl[\"ID\"]))\n",
        "\n",
        "  # print(c)\n",
        "  # print(\"STRING:\", len(tab), \"| ClusterProfiler:\", len(tab_cl))\n",
        "  # print(\"Intersection\", len(inter))\n",
        "  # print(\"Union\", len(union))\n",
        "  # print(f\"Overlap: {len(inter)/min(len(tab),len(tab_cl)):.2f}\")\n",
        "  # print(f\"Jaccard: {len(inter)/len(union):.2f}\\n\")\n",
        "\n",
        "  STRING = set(tab[\"ID\"])\n",
        "  CLUSTER = set(tab_cl[\"ID\"])\n",
        "  GSEAPY = set(tab_gs[\"ID\"])\n",
        "\n",
        "  results_dict[c] = {\"STRING\":tab,\"ClusterProfiler\":tab_cl,\"GSEApy\":tab_gs}\n",
        "\n",
        "  ############ PLOTTING\n",
        "\n",
        "  fig, ax = plt.subplots(1,1, figsize=(4,4))\n",
        "\n",
        "  venn3(subsets=[STRING, CLUSTER, GSEAPY], set_labels = ('STRING', 'ClusterProfiler', 'GSEApy'),ax=ax)\n",
        "\n",
        "  ax.set_title(f\"{c}\")\n",
        "  # param_info = f\"{c}\\nFDR < {fdr:.0%}\\nGO (BP,MF,CC)\\n{metric}\"\n",
        "  # props = dict(boxstyle='round', facecolor='lightgrey', alpha=0.5)\n",
        "  # ax.text(1.1, 0.5, param_info, transform=ax.transAxes, fontsize=12,\n",
        "  #       verticalalignment='center', bbox=props)\n",
        "  # plt.subplots_adjust(right=0.8)\n",
        "\n",
        "  fig.tight_layout()\n",
        "  figpath = f\"{plotpath}/venn3.enrichment.{c}.{metric}.{paramset}.pdf\"\n",
        "  fig.savefig(figpath,bbox_inches='tight')\n",
        "  print(figpath)"
      ],
      "metadata": {
        "id": "vzN2WsN6C50G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top terms"
      ],
      "metadata": {
        "id": "0HD3LBMFt4ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_intersection_depths(df_list):\n",
        "\n",
        "  # Create a defaultdict to count occurrences\n",
        "  element_counts = defaultdict(int)\n",
        "\n",
        "  # Count occurrences of elements across subsets\n",
        "  for subset in subsets:\n",
        "      for element in subset:\n",
        "          element_counts[element] += 1\n",
        "\n",
        "  return element_counts\n",
        "\n",
        "#for c in contrasts:\n",
        "c = \"KO_WT\"\n",
        "\n",
        "def combine_dfs(results_dict):\n",
        "\n",
        "  for method in [\"STRING\",\"ClusterProfiler\",\"GSEApy\"]:\n",
        "\n",
        "    tab = results_dict[c][method]\n",
        "    tab[\"Method\"] = method\n",
        "\n",
        "    match method:\n",
        "      case \"STRING\":\n",
        "        tab.rename({\"false discovery rate\": \"p.adj\",\n",
        "                    \"term description\":\"Term\"}, axis=1, inplace=True)\n",
        "        tab[\"Direction\"] = tab['direction'].apply(lambda x: 'Up' if x == \"top\" else ('Both' if x == \"both ends\" else 'Down'))\n",
        "      case \"ClusterProfiler\":\n",
        "        tab.rename({\"qvalue\": \"p.adj\",\n",
        "                    \"Description\":\"Term\"}, axis=1, inplace=True)\n",
        "        tab[\"Direction\"] = tab['NES'].apply(lambda x: 'Up' if x > 0 else ('Both' if x == 0 else 'Down'))\n",
        "      case \"GSEApy\":\n",
        "        tab.rename({\"FDR q-val\": \"p.adj\"}, axis=1, inplace=True)\n",
        "        tab[\"Direction\"] = tab['NES'].apply(lambda x: 'Up' if x > 0 else ('Both' if x == 0 else 'Down'))\n",
        "\n",
        "  combined= pd.concat([results_dict[c][\"STRING\"][[\"ID\",\"p.adj\",\"Method\",\"Direction\",\"Term\"]],\n",
        "                       results_dict[c][\"ClusterProfiler\"][[\"ID\",\"p.adj\",\"Method\",\"Direction\",\"Term\"]],\n",
        "                       results_dict[c][\"GSEApy\"][[\"ID\",\"p.adj\",\"Method\",\"Direction\",\"Term\"]]\n",
        "                      ])\n",
        "\n",
        "  combined[\"ID_Direction\"] = combined[\"ID\"] + \" \" + combined[\"Direction\"]\n",
        "  combined[\"Counts\"] = combined.groupby(['ID_Direction'])['ID_Direction'].transform('count')\n",
        "  combined.sort_values(by=[\"Counts\",\"p.adj\"], ascending=[False,True], inplace=True)\n",
        "  combined = combined[[\"ID\",\"Counts\",\"p.adj\",\"Direction\",\"Method\",\"Term\",\"ID_Direction\"]]\n",
        "  return combined.reset_index(drop=True)\n",
        "\n",
        "combined  = combine_dfs(results_dict)"
      ],
      "metadata": {
        "id": "OW6MNbtZ8JM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined.to_csv(f\"{csvpath}/Enrichment/combined.csv\")\n",
        "combined"
      ],
      "metadata": {
        "id": "V3NzToX5TIwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined[combined[\"Counts\"]>2].sort_values(by=\"ID\")"
      ],
      "metadata": {
        "id": "NAIHLVM2ufT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inter = combined[\"ID\"].value_counts()\n",
        "inter = inter[inter > 2]\n",
        "combined[combined[\"ID\"].isin(inter.index.values)]"
      ],
      "metadata": {
        "id": "AD4tji7XSnNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metric comparison"
      ],
      "metadata": {
        "id": "P8eBThS5EuRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib_venn import venn2\n",
        "\n",
        "metric1 = \"lfc\"\n",
        "metric2 = \"signed_logpval\"\n",
        "\n",
        "for c in contrasts:\n",
        "  f = f\"{csvpath}/Enrichment/string/{c}.{metric1}.enrichment.all.{paramset}.tsv\"\n",
        "  tab = pd.read_csv(f, sep=\"\\t\")\n",
        "  tab = tab[(tab[\"#category\"].str.startswith(\"GO\")) | (tab[\"#category\"].str.startswith(\"KEGG\"))]\n",
        "\n",
        "  f = f\"{csvpath}/Enrichment/string//{c}.{metric2}.enrichment.all.{paramset}.tsv\"\n",
        "  tab2 = pd.read_csv(f, sep=\"\\t\")\n",
        "  tab2 = tab2[(tab2[\"#category\"].str.startswith(\"GO\")) | (tab2[\"#category\"].str.startswith(\"KEGG\"))]\n",
        "\n",
        "  # JACCARD\n",
        "  inter = set(tab[\"term ID\"]).intersection(set(tab2[\"term ID\"]))\n",
        "  union = set(tab[\"term ID\"]).union(set(tab2[\"term ID\"]))\n",
        "\n",
        "  print(c)\n",
        "  print(f\"{metric1}:\", len(tab), f\"| {metric2}:\", len(tab2))\n",
        "  print(\"Intersection\", len(inter))\n",
        "  print(\"Union\", len(union))\n",
        "  print(f\"Overlap: {len(inter)/min(len(tab),len(tab2)):.2f}\")\n",
        "  print(f\"Jaccard: {len(inter)/len(union):.2f}\\n\")\n",
        "\n",
        "\n",
        "  STRING1 = set(tab[\"term ID\"])\n",
        "  STRING2 = set(tab2[\"term ID\"])\n",
        "\n",
        "  fig, ax = plt.subplots(1,1, figsize=(4,4))\n",
        "\n",
        "  venn2(subsets=[STRING1, STRING2], set_labels = (\"logFC\",\"signed_logpval\"),ax=ax)\n",
        "\n",
        "  ax.set_title(f\"{c}\")\n",
        "\n",
        "  # param_info = f\"{c}\\nFDR < {fdr:.0%}\\nGO (BP,MF,CC)\"\n",
        "  # props = dict(boxstyle='round', facecolor='lightgrey', alpha=0.5)\n",
        "  # ax.text(1.1, 0.5, param_info, transform=ax.transAxes, fontsize=12,\n",
        "  #       verticalalignment='center', bbox=props)\n",
        "  # plt.subplots_adjust(right=0.8)\n",
        "\n",
        "  fig.tight_layout()\n",
        "  figpath = f\"{plotpath}/venn2.enrichment.{c}.STRING.{paramset}.pdf\"\n",
        "  fig.savefig(figpath,bbox_inches='tight')\n",
        "  print(figpath)"
      ],
      "metadata": {
        "id": "hSO7JKThDS6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "keukKxdZDwl1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}