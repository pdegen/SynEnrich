{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import yaml\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "palette = sns.color_palette()\n",
    "pd.options.mode.copy_on_write = True\n",
    "scripts_dir = os.path.abspath(os.path.join(os.getcwd(), \"../scripts\"))\n",
    "sys.path.append(scripts_dir)\n",
    "workflows_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(workflows_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define params\n",
    "\n",
    "- `input_file`: Path (relative to project root) to a csv file containing a table with gene names and ranking metric(s). Input files should be put in the `resources` folder.\n",
    "  \n",
    "- `project_name`: A string to tag output files. Results will be saved in `results/{project_name}/some_filename.{project_name}.csv`\n",
    "\n",
    "- `metrics`: A list of strings specifying columns in the input table that are used to rank the genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### User-defined variables ####\n",
    "\n",
    "input_file = \"resources/Chiara/edger.lrt.lfc0.KO_WT.p1.csv\"\n",
    "project_name = \"test2\"\n",
    "\n",
    "metrics = ['logFC', 'neg_signed_logpval']#, 'signed_LR']\n",
    "libraries = [\"KEGG\",\"GO\"]\n",
    "tools = [\"clusterProfiler\",\"gseapy\"]\n",
    "\n",
    "\n",
    "# ClusterProfiler\n",
    "\n",
    "keytype = \"ENSEMBL\"\n",
    "organismKEGG = \"hsa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### User-defined variables ####\n",
    "\n",
    "input_file = \"resources/Liana/deg.edger.lrt.batch.unm_0.6.clean.clExc7_DL.thresh.0.2.2024-01-22-17-42.P90.p19rc.csv\"\n",
    "project_name = \"met.Exc7_DL.P90.p19rc\"\n",
    "\n",
    "metrics = ['logFC', 'neg_signed_logpval']\n",
    "libraries = [\"KEGG\",\"GO\"]\n",
    "tools = [\"clusterProfiler\",\"gseapy\",\"string\"]\n",
    "\n",
    "\n",
    "# ClusterProfiler\n",
    "\n",
    "keytype = \"SYMBOL\"\n",
    "organismKEGG = \"mmu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create config.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration dictionary\n",
    "config_data = {\n",
    "    'input_file': input_file,\n",
    "    'project_name': project_name,\n",
    "    'metrics': metrics,\n",
    "    'keytype': keytype,\n",
    "    'organismKEGG': organismKEGG,\n",
    "    'libraries': libraries,\n",
    "    'tools': tools\n",
    "}\n",
    "\n",
    "# Write to config.yaml\n",
    "config_filename = \"../../config/config.yaml\"\n",
    "with open(config_filename, 'w') as file:\n",
    "    yaml.dump(config_data, file, default_flow_style=False)\n",
    "\n",
    "print(f\"Configuration file '{config_filename}' created successfully!\")\n",
    "\n",
    "savepath = f\"../../results/{project_name}/\"\n",
    "figpath = f\"../../results/{project_name}/figures/\"\n",
    "!mkdir $figpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect/modify input\n",
    "\n",
    "This space can be used to calculate further ranking metrics that are missing in the input table. As an example, we read the output from edgeR and calculate $-\\mathrm{sign}(\\log_2\\mathrm{FC})\\times\\log_{10}(p\\mathrm{-value})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../../{input_file}\", index_col=0)\n",
    "df[\"neg_signed_logpval\"] = -np.sign(df[\"logFC\"]) * np.log10(df[\"PValue\"])\n",
    "df[\"signed_LR\"] = np.sign(df[\"logFC\"]) * df[\"LR\"]\n",
    "display(df.head())\n",
    "#df.to_csv(f\"../../{input_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations\n",
    "\n",
    "Inspect correlations between the two different ranking metrics (e.g. logFC and signed pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank1 = \"logFC\"\n",
    "rank2 = \"neg_signed_logpval\"\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "### Pearson correlation\n",
    "\n",
    "correlation = df[rank1].corr(df[rank2], method='pearson')\n",
    "sns.regplot(x=df[rank1], y=df[\"neg_signed_logpval\"], ax=ax[0], scatter_kws={'alpha':0.1}, line_kws={\"color\":palette[3]})\n",
    "ax[0].set_title(f\"Pearson: {correlation:.2f}\")\n",
    "\n",
    "ax[0].set(xlabel=rank1)\n",
    "ax[0].set(ylabel=\"-sign(logFC)*log10(p-value)\")\n",
    "\n",
    "### Spearman rank correlation\n",
    "\n",
    "df['rank1'] = df[rank1].rank(method='average')\n",
    "df['rank2'] = df[rank2].rank(method='average')\n",
    "rank_correlation = df['rank1'].corr(df['rank2'], method='spearman')\n",
    "\n",
    "sns.regplot(x=df['rank1'] ,y=df['rank2'], ax=ax[1], scatter_kws={'alpha':0.01}, line_kws={\"color\":palette[3]})\n",
    "ax[1].set_title(f\"Spearman: {rank_correlation:.2f}\")\n",
    "fig.tight_layout()\n",
    "\n",
    "ax[1].set(xlabel=\"logFC [Rank]\")\n",
    "ax[1].set(ylabel=\"-sign(logFC)*log10(p-value) [Rank]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Snakemake\n",
    "\n",
    "Run the following command in project root directory:\n",
    "\n",
    "`snakemake --use-conda --cores 1` (adjust number of cores as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# cores = 1\n",
    "# command = f\"snakemake -s ../Snakefile --configfile ../../config/config.yaml --use-conda --cores {cores}\"\n",
    "# subprocess.run(command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "palette = sns.color_palette()\n",
    "\n",
    "output_files = glob.glob(f\"{savepath}/syn.*[tc]sv\")\n",
    "print(f\"Found {len(output_files)} output files:\\n\",*[o+\"\\n\" for o in output_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dict = {lib: dict() for lib in libraries}\n",
    "for lib in libraries:\n",
    "    summary_df = pd.read_csv(f\"{savepath}/syn.combined.{lib}.{project_name}.csv\", index_col=0, header=[0,1,2])\n",
    "    summary_df.sort_values(by=(\"Combined\",\"nan\",\"Stouffer FDR\"))\n",
    "    summary_dict[lib][\"summary_df\"] = summary_df\n",
    "\n",
    "summary_df = summary_dict[libraries[1]][\"summary_df\"]\n",
    "print(libraries[0], len(summary_df))\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scripts import explore_results\n",
    "# import importlib\n",
    "# importlib.reload(explore_results)\n",
    "\n",
    "from scripts.explore_results import get_sig_dict, create_intersection_depth_df\n",
    "\n",
    "qval = 0.05\n",
    "\n",
    "for lib in summary_dict:\n",
    "    print(lib)\n",
    "    summary_df = summary_dict[lib][\"summary_df\"]\n",
    "    sig_dict = get_sig_dict(summary_df, tools, metrics, qval=qval)\n",
    "    summary_dict[lib][\"depth_df\"] = create_intersection_depth_df(sig_dict)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection depth\n",
    "\n",
    "We count the number of unique analysis configuations (methods, rankings) each significant term appears in. We designate this as the *intersection depth* of a term. A depth of $N$ means that the corresponding enrichment term is significant in exactly $N$ configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,3))\n",
    "\n",
    "for ax, lib in zip(axes,summary_dict):\n",
    "    depth_df = summary_dict[lib][\"depth_df\"]\n",
    "    h = sns.histplot(depth_df['Depth'], bins=depth_df['Depth'].max() - depth_df['Depth'].min() + 1, \n",
    "                 discrete=True, ax=ax, alpha=1)\n",
    "    h.bar_label(h.containers[0])\n",
    "    ax.set(title=lib, xlabel=\"Depth\", ylabel=\"Terms\")\n",
    "    ax.set_xticks(range(depth_df['Depth'].min(), depth_df['Depth'].max() + 1))\n",
    "    ax.grid(axis='x')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{figpath}/intersection_depth.{project_name}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "for ax, lib in zip(axes,summary_dict):\n",
    "    summary_df = summary_dict[lib][\"summary_df\"]\n",
    "    qv = summary_df.drop([\"Combined\",\"nan\"], axis=1, level=0)\n",
    "    qv = qv.xs(\"qvalue\", level=2, axis=1)\n",
    "    qv = qv.replace(np.nan,1)\n",
    "    qv = qv < qval\n",
    "\n",
    "    qqv=qv.sum().reset_index()\n",
    "    qqv.index = qqv[\"Tool\"] + \"\\n\" + qqv[\"Metric\"]\n",
    "    qqv = qqv.drop([\"Tool\",\"Metric\"], axis=1)\n",
    "    qqv = qqv.sort_values(by=qqv.columns[0], ascending=False)\n",
    "\n",
    "    b = sns.barplot(x=qqv.index, y=qqv.iloc[:, 0], ax=ax, alpha=1)\n",
    "    for i in b.containers:\n",
    "        b.bar_label(i,)\n",
    "    ax.set_xticks(ax.get_xticks(), ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    ax.set(title=lib, ylabel=\"Terms\", xlabel=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{figpath}/number_sig_terms.{project_name}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Venn diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "from matplotlib_venn import venn2, venn3\n",
    "\n",
    "def plot_venn(summary_df, tools, metrics):\n",
    "    n_sets = len(tools) * len(metrics)\n",
    "    if n_sets not in [2,3,4]:\n",
    "        raise Exception(f\"Venn diagram with {n_sets} sets not supported\")\n",
    "    return\n",
    "\n",
    "plot_venn(summary_df, tools[:2], metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UpSet plots\n",
    "\n",
    "Useful for visualizing set intersection with more than 3 sets. \n",
    "\n",
    "https://upsetplot.readthedocs.io/en/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from upsetplot import from_memberships\n",
    "from upsetplot import UpSet\n",
    "\n",
    "depth_df = summary_dict[lib][\"depth_df\"]\n",
    "memberships = depth_df[\"Factors\"]\n",
    "memberships_list = [categories.split(\" | \") for categories in memberships.values]\n",
    "upset_ready = from_memberships(memberships_list)\n",
    "\n",
    "pd.options.mode.copy_on_write = False\n",
    "UpSet(upset_ready, subset_size=\"count\", sort_by=\"cardinality\").plot()\n",
    "pd.options.mode.copy_on_write = True\n",
    "pyplot.savefig(f\"{figpath}/upset.{project_name}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format STRING table\n",
    "\n",
    "User can (optionally) manually add STRING functional scoring output tables to the results folder, and they will be combined with the output from SynEnrich. For this, STRING tables have to be formatted first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import format_string_table\n",
    "\n",
    "string_file = f\"{savepath}/syn.string.logFC.{project_name}.tsv\"\n",
    "string_file = f\"{savepath}/syn.string.neg_signed_logpval.{project_name}.tsv\"\n",
    "string = pd.read_csv(string_file, index_col=0, sep=\"\\t\")\n",
    "\n",
    "for library in [\"GO\", \"KEGG\"]:\n",
    "    string_formatted = format_string_table(string, library)\n",
    "    display(string_formatted.head())\n",
    "    string_formatted.to_csv(string_file.replace(f\"{project_name}.tsv\", f\"{library}.{project_name}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ClusterProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "source(\"../../.Rprofile\")\n",
    ".libPaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i input_file\n",
    "library(clusterProfiler)\n",
    "library(org.Hs.eg.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "filepath <- paste0(\"../../\",input_file)\n",
    "\n",
    "metrics = c(\"neg_signed_logpval\",\"logFC\")\n",
    "\n",
    "df <- read.csv(filepath, row.names = 1)\n",
    "\n",
    "for (metric in metrics) {\n",
    "    # Check if the metric is in the columns\n",
    "    if (!(metric %in% colnames(df))) {\n",
    "            if (metric == \"neg_signed_logpval\") {\n",
    "                message(paste(\"Adding\", metric, \"to df\"))\n",
    "                df$neg_signed_logpval <- -sign(df$logFC) * log10(df$PValue)\n",
    "            } else {\n",
    "                stop(paste(\"Metric\", metric, \"not in columns!\"))\n",
    "            }\n",
    "        }\n",
    "}\n",
    "\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "run_clusterProfiler <- function(df, savepath, paramset,\n",
    "                                metric, cluster, overwrite=FALSE, \n",
    "                                organism.KEGG=\"hsa\",\n",
    "                                organism.GO = org.Hs.eg.db, seed=123) \n",
    "{\n",
    "  set.seed(seed)\n",
    "\n",
    "  outfile_go <- paste0(savepath,\"/cluster.gseGO.\",metric,\".\",paramset,\".csv\")\n",
    "  outfile_kegg <- paste0(savepath,\"/cluster.gseKEGG.\",metric,\".\",paramset,\".csv\")\n",
    "  print(outfile_go)\n",
    "  print(outfile_kegg)\n",
    "\n",
    "  if (file.exists(outfile_go) && file.exists(outfile_kegg) && !overwrite) {\n",
    "    print(\"Existing files not overwritte, skipping\")\n",
    "    return\n",
    "  }\n",
    "\n",
    "  start_time <- Sys.time()\n",
    "\n",
    "  geneList <- df[[metric]]\n",
    "  names(geneList) <- df$ENTREZID\n",
    "  geneList = sort(geneList, decreasing = TRUE)\n",
    "\n",
    "  if (!file.exists(outfile_go) || overwrite) {\n",
    "\n",
    "    ego3 <- gseGO(geneList     = geneList,\n",
    "                  OrgDb        = organism.GO,\n",
    "                  ont          = \"ALL\", ## CC MF BP\n",
    "                  minGSSize    = 10,\n",
    "                  maxGSSize    = 500,\n",
    "                  pvalueCutoff = 1,\n",
    "                  eps = 0,\n",
    "                  seed = TRUE,\n",
    "                  verbose = FALSE)\n",
    "    write.csv(ego3,outfile_go)\n",
    "  }\n",
    "\n",
    "  if (!file.exists(outfile_kegg) || overwrite) {\n",
    "\n",
    "    kegg <- gseKEGG(geneList     = geneList,\n",
    "                  organism        =  organism.KEGG,\n",
    "                  minGSSize    = 10,\n",
    "                  maxGSSize    = 500,\n",
    "                  pvalueCutoff = 1,\n",
    "                  eps = 0,\n",
    "                  seed = TRUE,\n",
    "                  verbose = FALSE)\n",
    "    write.csv(kegg,outfile_kegg)\n",
    "  }\n",
    "\n",
    "  end_time <- Sys.time()\n",
    "  print(end_time - start_time)\n",
    "}\n",
    "\n",
    "convert_df <- function(df, OrgDb=org.Hs.eg.db) {\n",
    "\n",
    "  if (\"ENTREZID\" %in% names(df)) return(df)\n",
    "  \n",
    "  df$ENSEMBL <- row.names(df)\n",
    "  # Convert to ENTREZ ID\n",
    "  # We will lose some genes here because not all IDs will be converted\n",
    "\n",
    "  ids<-bitr(row.names(df), fromType = \"ENSEMBL\", toType = \"ENTREZID\", OrgDb=OrgDb)\n",
    "  df <- merge(df, ids, by = \"ENSEMBL\", all.x = TRUE)\n",
    "  print(paste(\"Before\",nrow(df)))\n",
    "  df <- na.omit(df)\n",
    "  print(paste(\"After\",nrow(df)))\n",
    "  return(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "df <- convert_df(df, OrgDb=org.Hs.eg.db)\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i project_name\n",
    "savepath <- paste0(\"../../results/\",project_name)\n",
    "paramset <- \"test\"\n",
    "metric <- \"neg_signed_logpval\"\n",
    "df <- convert_df(df, OrgDb=org.Hs.eg.db)\n",
    "run_clusterProfiler(df, savepath, paramset,\n",
    "                                metric, overwrite=FALSE, \n",
    "                                organism.KEGG=\"hsa\",\n",
    "                                organism.GO = org.Hs.eg.db) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SynEnrich",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
