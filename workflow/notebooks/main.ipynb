{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import yaml\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "palette = sns.color_palette()\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define params\n",
    "\n",
    "- `input_file`: Path (relative to project root) to a csv file containing a table with gene names and ranking metric(s). Input files should be put in the `resources` folder.\n",
    "  \n",
    "- `project_name`: A string to tag output files. Results will be saved in `results/{project_name}/some_filename.{project_name}.csv`\n",
    "\n",
    "- `metrics`: A list of string specifying columns in the input table that are used to rank the genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### User-defined variables ####\n",
    "\n",
    "input_file = \"resources/Chiara/edger.lrt.lfc0.KO_WT.p1.csv\"\n",
    "project_name = \"test2\"\n",
    "\n",
    "metrics = ['logFC', 'neg_signed_logpval']#, 'signed_LR']\n",
    "libraries = [\"KEGG\",\"GO\"]\n",
    "tools = [\"clusterProfiler\",\"gseapy\"]\n",
    "\n",
    "\n",
    "# ClusterProfiler\n",
    "\n",
    "keytype = \"ENSEMBL\"\n",
    "organismKEGG = \"hsa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### User-defined variables ####\n",
    "\n",
    "input_file = \"resources/Liana/deg.edger.lrt.batch.unm_0.6.clean.clExc7_DL.thresh.0.2.2024-01-22-17-42.P90.p19rc.csv\"\n",
    "project_name = \"met.Exc7_DL.P90.p19rc\"\n",
    "\n",
    "metrics = ['logFC', 'neg_signed_logpval']\n",
    "libraries = [\"KEGG\",\"GO\"]\n",
    "tools = [\"clusterProfiler\",\"gseapy\",\"string\"]\n",
    "\n",
    "\n",
    "# ClusterProfiler\n",
    "\n",
    "keytype = \"SYMBOL\"\n",
    "organismKEGG = \"mmu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create config.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration dictionary\n",
    "config_data = {\n",
    "    'input_file': input_file,\n",
    "    'project_name': project_name,\n",
    "    'metrics': metrics,\n",
    "    'keytype': keytype,\n",
    "    'organismKEGG': organismKEGG,\n",
    "    'libraries': libraries,\n",
    "    'tools': tools\n",
    "}\n",
    "\n",
    "# Write to config.yaml\n",
    "config_filename = \"../../config/config.yaml\"\n",
    "with open(config_filename, 'w') as file:\n",
    "    yaml.dump(config_data, file, default_flow_style=False)\n",
    "\n",
    "print(f\"Configuration file '{config_filename}' created successfully!\")\n",
    "\n",
    "savepath = f\"../../results/{project_name}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect/modify input\n",
    "\n",
    "This space can be used to calculate further ranking metrics that are missing in the input table, such as $-\\mathrm{sign}(\\log_2\\mathrm{FC})\\times\\log_{10}(p\\mathrm{-value})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../../{input_file}\", index_col=0)\n",
    "df[\"neg_signed_logpval\"] = -np.sign(df[\"logFC\"]) * np.log10(df[\"PValue\"])\n",
    "df[\"signed_LR\"] = np.sign(df[\"logFC\"]) * df[\"LR\"]\n",
    "display(df.head())\n",
    "#df.to_csv(f\"../../{input_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Snakemake\n",
    "\n",
    "Run the following command in project root directory:\n",
    "\n",
    "`snakemake --use-conda --cores 1` (adjust number of cores as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# cores = 1\n",
    "# command = f\"snakemake -s ../Snakefile --configfile ../../config/config.yaml --use-conda --cores {cores}\"\n",
    "# subprocess.run(command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "palette = sns.color_palette()\n",
    "\n",
    "output_files = glob.glob(f\"{savepath}/syn.*[tc]sv\")\n",
    "print(f\"Found {len(output_files)} output files:\\n\",*[o+\"\\n\" for o in output_files])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "### Pearson correlation\n",
    "\n",
    "correlation = df[\"logFC\"].corr(df[\"neg_signed_logpval\"], method='pearson')\n",
    "sns.regplot(x=df[\"logFC\"], y=df[\"neg_signed_logpval\"], ax=ax[0], scatter_kws={'alpha':0.1}, line_kws={\"color\":palette[3]})\n",
    "ax[0].set_title(f\"Pearson: {correlation:.2f}\")\n",
    "\n",
    "ax[0].set(xlabel=\"logFC\")\n",
    "ax[0].set(ylabel=\"-sign(logFC)*log10(p-value)\")\n",
    "\n",
    "### Spearman rank correlation\n",
    "\n",
    "df['rank_lfc'] = df['logFC'].rank(method='average')\n",
    "df['rank_nslp'] = df['neg_signed_logpval'].rank(method='average')\n",
    "rank_correlation = df['rank_lfc'].corr(df['rank_nslp'], method='spearman')\n",
    "\n",
    "sns.regplot(x=df['rank_lfc'] ,y=df['rank_nslp'], ax=ax[1], scatter_kws={'alpha':0.01}, line_kws={\"color\":palette[3]})\n",
    "ax[1].set_title(f\"Spearman: {rank_correlation:.2f}\")\n",
    "fig.tight_layout()\n",
    "\n",
    "ax[1].set(xlabel=\"logFC [Rank]\")\n",
    "ax[1].set(ylabel=\"-sign(logFC)*log10(p-value) [Rank]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Venn diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = libraries[1]\n",
    "print(lib)\n",
    "\n",
    "summary_df = pd.read_csv(f\"{savepath}/syn.combined.{lib}.{project_name}.csv\", index_col=0, header=[0,1,2])\n",
    "summary_df.sort_values(by=(\"Combined\",\"nan\",\"Stouffer FDR\"))\n",
    "print(len(summary_df))\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "from matplotlib_venn import venn2, venn3\n",
    "\n",
    "def plot_venn(summary_df, metrics):\n",
    "    return\n",
    "\n",
    "plot_venn(summary_df, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=summary_df.xs((\"neg_signed_logpval\",\"pvalue\"), axis=1)\n",
    "y=summary_df.xs((\"Combined\",\"Stouffer FDR\"), axis=1)\n",
    "sns.regplot(x=x,y=y)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df[(\"Combined\",\"enrichmentScore SD\")].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format STRING table\n",
    "\n",
    "User can (optionally) manually add STRING functional scoring output tables to the resutls folder, and they will be combined with the output from SynEnrich. For this, STRING tables have to be formatted first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_string_table(df: pd.DataFrame, library: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Format table from STRING databse functional scoring results (proteins with values/ranks)\n",
    "    Output will look closer to ClusterProfiler table\n",
    "    \"\"\"\n",
    "\n",
    "    df.loc[:,\"ONTOLOGY\"] = df.index\n",
    "\n",
    "    match library:\n",
    "        case \"GO\":\n",
    "            df = df[df.index.str.startswith(\"GO \")]\n",
    "            df.replace({\"ONTOLOGY\" : \"GO Process\"}, \"BP\", inplace=True)\n",
    "            df.replace({\"ONTOLOGY\" : \"GO Function\"}, \"MF\", inplace=True)\n",
    "            df.replace({\"ONTOLOGY\" : \"GO Component\"}, \"CC\", inplace=True)\n",
    "        case \"KEGG\":\n",
    "            df = df[df.index.str.startswith(\"KEGG\")]\n",
    "        case _:\n",
    "            raise Exception(\"Unknown library:\", library)\n",
    "        \n",
    "    df.rename({\"enrichment score\": \"enrichmentScore\",\n",
    "               \"term description\": \"Description\",\n",
    "               \"term ID\": \"ID\",\n",
    "               \"false discovery rate\": \"qvalue\"},\n",
    "              axis=1, inplace=True)\n",
    "    df.set_index(\"ID\", inplace=True)\n",
    "\n",
    "    df[\"pvalue\"] = df[\"qvalue\"] # dubious but STRING doesn't save pvalues...\n",
    "\n",
    "    # STRING sort values from negative to positive, hence \"top\" will be downregulated, hence reverse this here\n",
    "    df[\"enrichmentScore\"] = df[\"enrichmentScore\"] * df[\"direction\"].apply(lambda x: -1 if x == \"top\" else 1 if x == \"bottom\" else 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_file = f\"{savepath}/syn.string.logFC.{project_name}.tsv\"\n",
    "string = pd.read_csv(string_file, index_col=0, sep=\"\\t\")\n",
    "\n",
    "for library in [\"GO\", \"KEGG\"]:\n",
    "    string_formatted = format_string_table(string, library)\n",
    "    display(string_formatted.head())\n",
    "    string_formatted.to_csv(string_file.replace(f\"{project_name}.tsv\", f\"{library}.{project_name}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ClusterProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "source(\"../../.Rprofile\")\n",
    ".libPaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i input_file\n",
    "library(clusterProfiler)\n",
    "library(org.Hs.eg.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "filepath <- paste0(\"../../\",input_file)\n",
    "\n",
    "metrics = c(\"neg_signed_logpval\",\"logFC\")\n",
    "\n",
    "df <- read.csv(filepath, row.names = 1)\n",
    "\n",
    "for (metric in metrics) {\n",
    "    # Check if the metric is in the columns\n",
    "    if (!(metric %in% colnames(df))) {\n",
    "            if (metric == \"neg_signed_logpval\") {\n",
    "                message(paste(\"Adding\", metric, \"to df\"))\n",
    "                df$neg_signed_logpval <- -sign(df$logFC) * log10(df$PValue)\n",
    "            } else {\n",
    "                stop(paste(\"Metric\", metric, \"not in columns!\"))\n",
    "            }\n",
    "        }\n",
    "}\n",
    "\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "run_clusterProfiler <- function(df, savepath, paramset,\n",
    "                                metric, cluster, overwrite=FALSE, \n",
    "                                organism.KEGG=\"hsa\",\n",
    "                                organism.GO = org.Hs.eg.db, seed=123) \n",
    "{\n",
    "  set.seed(seed)\n",
    "\n",
    "  outfile_go <- paste0(savepath,\"/cluster.gseGO.\",metric,\".\",paramset,\".csv\")\n",
    "  outfile_kegg <- paste0(savepath,\"/cluster.gseKEGG.\",metric,\".\",paramset,\".csv\")\n",
    "  print(outfile_go)\n",
    "  print(outfile_kegg)\n",
    "\n",
    "  if (file.exists(outfile_go) && file.exists(outfile_kegg) && !overwrite) {\n",
    "    print(\"Existing files not overwritte, skipping\")\n",
    "    return\n",
    "  }\n",
    "\n",
    "  start_time <- Sys.time()\n",
    "\n",
    "  geneList <- df[[metric]]\n",
    "  names(geneList) <- df$ENTREZID\n",
    "  geneList = sort(geneList, decreasing = TRUE)\n",
    "\n",
    "  if (!file.exists(outfile_go) || overwrite) {\n",
    "\n",
    "    ego3 <- gseGO(geneList     = geneList,\n",
    "                  OrgDb        = organism.GO,\n",
    "                  ont          = \"ALL\", ## CC MF BP\n",
    "                  minGSSize    = 10,\n",
    "                  maxGSSize    = 500,\n",
    "                  pvalueCutoff = 1,\n",
    "                  eps = 0,\n",
    "                  seed = TRUE,\n",
    "                  verbose = FALSE)\n",
    "    write.csv(ego3,outfile_go)\n",
    "  }\n",
    "\n",
    "  if (!file.exists(outfile_kegg) || overwrite) {\n",
    "\n",
    "    kegg <- gseKEGG(geneList     = geneList,\n",
    "                  organism        =  organism.KEGG,\n",
    "                  minGSSize    = 10,\n",
    "                  maxGSSize    = 500,\n",
    "                  pvalueCutoff = 1,\n",
    "                  eps = 0,\n",
    "                  seed = TRUE,\n",
    "                  verbose = FALSE)\n",
    "    write.csv(kegg,outfile_kegg)\n",
    "  }\n",
    "\n",
    "  end_time <- Sys.time()\n",
    "  print(end_time - start_time)\n",
    "}\n",
    "\n",
    "convert_df <- function(df, OrgDb=org.Hs.eg.db) {\n",
    "\n",
    "  if (\"ENTREZID\" %in% names(df)) return(df)\n",
    "  \n",
    "  df$ENSEMBL <- row.names(df)\n",
    "  # Convert to ENTREZ ID\n",
    "  # We will lose some genes here because not all IDs will be converted\n",
    "\n",
    "  ids<-bitr(row.names(df), fromType = \"ENSEMBL\", toType = \"ENTREZID\", OrgDb=OrgDb)\n",
    "  df <- merge(df, ids, by = \"ENSEMBL\", all.x = TRUE)\n",
    "  print(paste(\"Before\",nrow(df)))\n",
    "  df <- na.omit(df)\n",
    "  print(paste(\"After\",nrow(df)))\n",
    "  return(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "df <- convert_df(df, OrgDb=org.Hs.eg.db)\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i project_name\n",
    "savepath <- paste0(\"../../results/\",project_name)\n",
    "paramset <- \"test\"\n",
    "metric <- \"neg_signed_logpval\"\n",
    "df <- convert_df(df, OrgDb=org.Hs.eg.db)\n",
    "run_clusterProfiler(df, savepath, paramset,\n",
    "                                metric, overwrite=FALSE, \n",
    "                                organism.KEGG=\"hsa\",\n",
    "                                organism.GO = org.Hs.eg.db) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SynEnrich",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
