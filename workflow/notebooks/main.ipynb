{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import yaml\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "palette = sns.color_palette()\n",
    "pd.options.mode.copy_on_write = True\n",
    "scripts_dir = os.path.abspath(os.path.join(os.getcwd(), \"../scripts\"))\n",
    "sys.path.append(scripts_dir)\n",
    "workflows_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(workflows_dir)\n",
    "\n",
    "# pretty print\n",
    "pretty_print = {\"string\": \"STRING\",\n",
    "      \"gseapy\": \"GSEApy\",\n",
    "      \"clusterProfiler\": \"ClusterProfiler\",\n",
    "      \"neg_signed_logpval\": \"signed logPValue\",\n",
    "      \"logFC\": \"logFC\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define params\n",
    "\n",
    "- `input_file`: Path (relative to project root) to a csv file containing a table with gene names and ranking metric(s). Input files should be put in the `resources` folder.\n",
    "  \n",
    "- `project_name`: A string to tag output files. Results will be saved in `results/{project_name}/some_filename.{project_name}.csv`\n",
    "\n",
    "- `metrics`: A list of strings specifying columns in the input table that are used to rank the genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### User-defined variables ####\n",
    "\n",
    "input_file = \"resources/Carmen/chk2_edgeR_tab_gene.csv\"\n",
    "project_name = \"chk2\"\n",
    "\n",
    "input_file = \"resources/Chiara/edger.lrt.lfc0.KO_WT.p1.csv\"\n",
    "project_name = \"Chiara.KO_WT\"\n",
    "\n",
    "input_file = \"resources/Chiara/edger.lrt.lfc0.SA_WT.p1.csv\"\n",
    "project_name = \"Chiara.SA_WT\"\n",
    "\n",
    "# input_file = \"resources/TCGA/BRCA.edgerlrt.lfc0.csv\"\n",
    "# project_name = \"BRCA.LRT\"\n",
    "\n",
    "metrics = ['logFC', 'neg_signed_logpval']\n",
    "libraries = [\"KEGG\",\"GO\"]\n",
    "tools = [\"clusterProfiler\",\"gseapy\",\"string\"]\n",
    "\n",
    "# ClusterProfiler\n",
    "\n",
    "keytype = \"ENSEMBL\"\n",
    "organismKEGG = \"hsa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### User-defined variables ####\n",
    "\n",
    "input_file = \"resources/Liana/deg.edger.lrt.batch.unm_0.6.clean.clExc7_DL.thresh.0.2.2024-01-22-17-42.P90.p19rc.csv\"\n",
    "project_name = \"met.Exc7_DL.P90.p19rc\"\n",
    "\n",
    "metrics = ['logFC', 'neg_signed_logpval']\n",
    "libraries = [\"KEGG\",\"GO\"]\n",
    "tools = [\"clusterProfiler\",\"gseapy\",\"string\"]\n",
    "\n",
    "# ClusterProfiler\n",
    "\n",
    "keytype = \"SYMBOL\"\n",
    "organismKEGG = \"mmu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create config.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration dictionary\n",
    "config_data = {\n",
    "    'input_file': input_file,\n",
    "    'project_name': project_name,\n",
    "    'metrics': metrics,\n",
    "    'keytype': keytype,\n",
    "    'organismKEGG': organismKEGG,\n",
    "    'libraries': libraries,\n",
    "    'tools': tools\n",
    "}\n",
    "\n",
    "# Write to config.yaml\n",
    "config_filename = \"../../config/config.yaml\"\n",
    "with open(config_filename, 'w') as file:\n",
    "    yaml.dump(config_data, file, default_flow_style=False)\n",
    "\n",
    "print(f\"Configuration file '{config_filename}' created successfully!\")\n",
    "\n",
    "savepath = f\"../../results/{project_name}/\"\n",
    "figpath = f\"../../results/{project_name}/figures/\"\n",
    "!mkdir -p $figpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect/modify input\n",
    "\n",
    "This space can be used to calculate further ranking metrics that are missing in the input table. As an example, we read the output table from edgeR, calculate $-\\mathrm{sign}(\\log_2\\mathrm{FC})\\times\\log_{10}(p\\mathrm{-value})$, and add this as a new column to the table.\n",
    "\n",
    "**Careful:** Updating input files after jobs have been run will re-run the jobs the next time Snakemake is run. To prevent this, you can use `--touch` to update the timestamps of previously generated output files:\n",
    "\n",
    "`snakemake --touch --cores 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../../{input_file}\", index_col=0)\n",
    "df[\"neg_signed_logpval\"] = -np.sign(df[\"logFC\"]) * np.log10(df[\"PValue\"])\n",
    "display(df.head())\n",
    "#df.to_csv(f\"../../{input_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations\n",
    "\n",
    "Inspect correlations between the two different ranking metrics (e.g. logFC and signed pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank1 = \"logFC\"\n",
    "rank2 = \"neg_signed_logpval\"\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "### Pearson correlation\n",
    "\n",
    "correlation = df[rank1].corr(df[rank2], method='pearson')\n",
    "sns.regplot(x=df[rank1], y=df[\"neg_signed_logpval\"], ax=ax[0], scatter_kws={'alpha':0.1}, line_kws={\"color\":palette[3]})\n",
    "ax[0].set_title(f\"Pearson: {correlation:.2f}\")\n",
    "\n",
    "ax[0].set(xlabel=rank1)\n",
    "ax[0].set(ylabel=\"-sign(logFC)*log10(p-value)\")\n",
    "\n",
    "### Spearman rank correlation\n",
    "\n",
    "df['rank1'] = df[rank1].rank(method='average')\n",
    "df['rank2'] = df[rank2].rank(method='average')\n",
    "rank_correlation = df['rank1'].corr(df['rank2'], method='spearman')\n",
    "\n",
    "sns.regplot(x=df['rank1'] ,y=df['rank2'], ax=ax[1], scatter_kws={'alpha':0.01}, line_kws={\"color\":palette[3]})\n",
    "ax[1].set_title(f\"Spearman: {rank_correlation:.2f}\")\n",
    "fig.tight_layout()\n",
    "\n",
    "ax[1].set(xlabel=\"logFC [Rank]\")\n",
    "ax[1].set(ylabel=\"-sign(logFC)*log10(p-value) [Rank]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Snakemake\n",
    "\n",
    "Run the following command in project root directory:\n",
    "\n",
    "`snakemake --use-conda --cores 1` (adjust number of cores as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# cores = 1\n",
    "# command = f\"snakemake -s ../Snakefile --configfile ../../config/config.yaml --use-conda --cores {cores}\"\n",
    "# subprocess.run(command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "palette = sns.color_palette()\n",
    "\n",
    "output_files = glob.glob(f\"{savepath}/syn.*[tc]sv\")\n",
    "print(f\"Found {len(output_files)} output files:\\n\",*[o+\"\\n\" for o in output_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dict = {lib: dict() for lib in libraries}\n",
    "for lib in libraries:\n",
    "    summary_df = pd.read_csv(f\"{savepath}/syn.combined.{lib}.{project_name}.csv\", index_col=0, header=[0,1,2])\n",
    "    summary_df.sort_values(by=(\"Combined\",\"nan\",\"Combined FDR\"))\n",
    "    summary_dict[lib][\"summary_df\"] = summary_df\n",
    "\n",
    "summary_df = summary_dict[libraries[1]][\"summary_df\"]\n",
    "print(libraries[0], len(summary_df))\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directionality\n",
    "# summary_df[(\"string\",\"logFC\",\"Direction\")].value_counts()\n",
    "# qv = summary_df.drop([\"Combined\",\"nan\"], axis=1, level=0)\n",
    "# qv = qv.xs(\"enrichmentScore\", level=2, axis=1)\n",
    "# qv.dropna(axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scripts import explore_results\n",
    "# import importlib\n",
    "# importlib.reload(explore_results)\n",
    "\n",
    "from scripts.explore_results import get_sig_dict, create_intersection_depth_df\n",
    "from scripts.utils import pickler\n",
    "\n",
    "qval = 0.05\n",
    "\n",
    "for lib in summary_dict:\n",
    "    print(lib)\n",
    "    summary_df = summary_dict[lib][\"summary_df\"]\n",
    "    sig_dict = get_sig_dict(summary_df, tools, metrics, qval=qval, verbose=True)\n",
    "    summary_dict[lib][\"depth_df\"] = create_intersection_depth_df(sig_dict)    \n",
    "\n",
    "# Store results in dictionary for meta-analysis\n",
    "pickler(summary_dict, f\"{savepath}/{project_name}.summary_dict.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection depth\n",
    "\n",
    "We count the number of unique analysis configuations (methods, rankings) each significant term appears in. We designate this as the *intersection depth* of a term. A depth of $N$ means that the corresponding enrichment term is significant in exactly $N$ configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,3))\n",
    "\n",
    "for ax, lib in zip(axes,summary_dict):\n",
    "    depth_df = summary_dict[lib][\"depth_df\"]\n",
    "    h = sns.histplot(depth_df['Depth'], bins=depth_df['Depth'].max() - depth_df['Depth'].min() + 1, \n",
    "                 discrete=True, ax=ax, alpha=1)\n",
    "    h.bar_label(h.containers[0])\n",
    "    ax.set(title=lib, xlabel=\"Depth\", ylabel=\"Terms\")\n",
    "    ax.set_xticks(range(depth_df['Depth'].min(), depth_df['Depth'].max() + 1))\n",
    "    ax.grid(axis='x')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{figpath}/intersection_depth.{project_name}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "for ax, lib in zip(axes,summary_dict):\n",
    "    summary_df = summary_dict[lib][\"summary_df\"]\n",
    "    qv = summary_df.drop([\"Combined\",\"nan\"], axis=1, level=0)\n",
    "    qv = qv.xs(\"qvalue\", level=2, axis=1)\n",
    "    qv = qv.replace(np.nan,1)\n",
    "    qv = qv < qval\n",
    "\n",
    "    qqv=qv.sum().reset_index()\n",
    "    qqv.replace({\"Tool\": pretty_print, \"Metric\": pretty_print}, inplace=True)\n",
    "    qqv.index = qqv[\"Tool\"] + \"\\n\" + qqv[\"Metric\"]\n",
    "    qqv = qqv.drop([\"Tool\",\"Metric\"], axis=1)\n",
    "    qqv = qqv.sort_values(by=qqv.columns[0], ascending=False)\n",
    "\n",
    "    b = sns.barplot(x=qqv.index, y=qqv.iloc[:, 0], ax=ax, alpha=1)\n",
    "    for i in b.containers:\n",
    "        b.bar_label(i,)\n",
    "    ax.set_xticks(ax.get_xticks(), ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    ax.set(title=lib, ylabel=\"Terms\", xlabel=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{figpath}/number_sig_terms.{project_name}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Venn diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.plots import plot_venn\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8,8))\n",
    "\n",
    "for i, lib in enumerate(libraries):\n",
    "    summary_df = summary_dict[lib][\"summary_df\"]\n",
    "    sig_dict = get_sig_dict(summary_df, tools, metrics, qval=0.05)\n",
    "    for j, metric in enumerate(metrics):\n",
    "        plot_venn(sig_dict, tools, metric, ax[i][j], pretty_print)\n",
    "        ax[i][j].set_title(f\"{pretty_print[metric]} ({lib})\", fontweight='bold')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{figpath}/venn.methodcomp.{project_name}.pdf\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(12,8))\n",
    "\n",
    "for i, lib in enumerate(libraries):\n",
    "    summary_df = summary_dict[lib][\"summary_df\"]\n",
    "    sig_dict = get_sig_dict(summary_df, tools, metrics, qval=0.05)\n",
    "    for j, tool in enumerate(tools):\n",
    "        plot_venn(sig_dict, tool, metrics, ax[i][j], pretty_print)\n",
    "        ax[i][j].set_title(f\"{pretty_print[tool]} ({lib})\", fontweight='bold')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{figpath}/venn.metriccomp.{project_name}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UpSet plots\n",
    "\n",
    "Useful for visualizing set intersection with more than 3 sets. \n",
    "\n",
    "https://upsetplot.readthedocs.io/en/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from upsetplot import from_memberships\n",
    "from upsetplot import UpSet\n",
    "\n",
    "for lib in libraries:\n",
    "\n",
    "    depth_df = summary_dict[lib][\"depth_df\"]\n",
    "    memberships = depth_df[\"Factors\"]\n",
    "    memberships_list = [categories.split(\" | \") for categories in memberships.values]\n",
    "    upset_ready = from_memberships(memberships_list)\n",
    "    upset_ready.index.names = [\" \".join([pretty_print[i] for i in u.split(\".\")]) for u in upset_ready.index.names] # pretty print\n",
    "\n",
    "    pd.options.mode.copy_on_write = False\n",
    "    UpSet(upset_ready, subset_size=\"count\", sort_by=\"cardinality\", show_counts=\"{:,}\").plot()\n",
    "    pd.options.mode.copy_on_write = True\n",
    "    pyplot.savefig(f\"{figpath}/upset.{lib}.{project_name}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-analysis\n",
    "\n",
    "Compare multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from scripts.plots import npg_palette\n",
    "\n",
    "npg = npg_palette()\n",
    "\n",
    "project_names = [\"BRCA.LRT\", \"chk2\", \"Chiara.KO_WT\", \"Chiara.SA_WT\", \"met.Exc7_DL.P90.p19rc\"]\n",
    "\n",
    "meta_dict = dict()\n",
    "for project in project_names:\n",
    "    try:\n",
    "        with open(f\"../../results/{project}/{project}.summary_dict.txt\", \"rb\") as f:\n",
    "            meta_dict[project] = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Project not found: {project}\")\n",
    "\n",
    "npg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_depth_dict = dict()\n",
    "\n",
    "for lib in libraries:\n",
    "    meta_depth_df = []\n",
    "    for project in meta_dict:\n",
    "        depth_df_p = meta_dict[project][lib][\"depth_df\"]\n",
    "        meta_depth_df.append(depth_df_p)\n",
    "\n",
    "    meta_depth_df = pd.concat(meta_depth_df)\n",
    "    meta_depth_dict[lib] = meta_depth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "for ax, lib in zip(axes,meta_depth_dict):\n",
    "    depth_df = meta_depth_dict[lib]\n",
    "    h = sns.histplot(depth_df['Depth'], bins=depth_df['Depth'].max() - depth_df['Depth'].min() + 1, \n",
    "                discrete=True, ax=ax, alpha=1, color=npg[3])\n",
    "    h.bar_label(h.containers[0])\n",
    "    ax.set(title=lib, xlabel=\"Intersection Depth\", ylabel=\"Terms\")\n",
    "    ax.set_xticks(range(depth_df['Depth'].min(), depth_df['Depth'].max() + 1))\n",
    "    ax.grid(axis='x')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../../results/meta/intersection_depth.meta.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_df[\"Depth\"].sum(), qqv.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_summary_dict = dict()\n",
    "\n",
    "for lib in libraries:\n",
    "    meta_summary_df = []\n",
    "    for project in meta_dict:\n",
    "        df = meta_dict[project][lib][\"summary_df\"]\n",
    "        df.index = df.index + \".\" + project # needed for venn\n",
    "        meta_summary_df.append(df)\n",
    "\n",
    "    meta_summary_df = pd.concat(meta_summary_df)\n",
    "    meta_summary_dict[lib] = meta_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "for ax, lib in zip(axes,meta_summary_dict):\n",
    "    summary_df = meta_summary_dict[lib]\n",
    "    qv = summary_df.drop([\"Combined\",\"nan\"], axis=1, level=0)\n",
    "    qv = qv.xs(\"qvalue\", level=2, axis=1)\n",
    "    qv = qv.replace(np.nan,1)\n",
    "    qv = qv < qval\n",
    "\n",
    "    qqv=qv.sum().reset_index()\n",
    "    qqv.replace({\"Tool\": pretty_print, \"Metric\": pretty_print}, inplace=True)\n",
    "    qqv.index = qqv[\"Tool\"] + \"\\n\" + qqv[\"Metric\"]\n",
    "    qqv = qqv.drop([\"Tool\",\"Metric\"], axis=1)\n",
    "    qqv = qqv.sort_values(by=qqv.columns[0], ascending=False)\n",
    "\n",
    "    b = sns.barplot(x=qqv.index, y=qqv.iloc[:, 0], ax=ax, alpha=1, color=npg[3])\n",
    "    for i in b.containers:\n",
    "        b.bar_label(i,)\n",
    "    ax.set_xticks(ax.get_xticks(), ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    ax.set(title=lib, ylabel=\"Terms\", xlabel=None)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../../results/meta/number_sig_terms.meta.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.plots import plot_venn\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8,8))\n",
    "\n",
    "for i, lib in enumerate(libraries):\n",
    "    summary_df = meta_summary_dict[lib]\n",
    "    sig_dict = get_sig_dict(summary_df, tools, metrics, qval=0.05)\n",
    "    for j, metric in enumerate(metrics):\n",
    "        plot_venn(sig_dict, tools, metric, ax[i][j], pretty_print)\n",
    "        ax[i][j].set_title(f\"{pretty_print[metric]} ({lib})\", fontweight='bold')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../../results/meta/venn.methodcomp.meta.pdf\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(12,8))\n",
    "\n",
    "for i, lib in enumerate(libraries):\n",
    "    summary_df = meta_summary_dict[lib]\n",
    "    sig_dict = get_sig_dict(summary_df, tools, metrics, qval=0.05)\n",
    "    for j, tool in enumerate(tools):\n",
    "        plot_venn(sig_dict, tool, metrics, ax[i][j], pretty_print)\n",
    "        ax[i][j].set_title(f\"{pretty_print[tool]} ({lib})\", fontweight='bold')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../../results/meta/venn.metriccomp.meta.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from upsetplot import from_memberships\n",
    "from upsetplot import UpSet\n",
    "\n",
    "for lib in libraries:\n",
    "\n",
    "    depth_df = meta_depth_dict[lib]\n",
    "    memberships = depth_df[\"Factors\"]\n",
    "    memberships_list = [categories.split(\" | \") for categories in memberships.values]\n",
    "    upset_ready = from_memberships(memberships_list)\n",
    "    upset_ready.index.names = [\" \".join([pretty_print[i] for i in u.split(\".\")]) for u in upset_ready.index.names] # pretty print\n",
    "\n",
    "    pd.options.mode.copy_on_write = False\n",
    "    UpSet(upset_ready, subset_size=\"count\", sort_by=\"cardinality\", show_counts=\"{:,}\", orientation=\"vertical\").plot()\n",
    "    pd.options.mode.copy_on_write = True\n",
    "    pyplot.savefig(f\"../../results/meta/upset.{lib}.meta.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format STRING table\n",
    "\n",
    "User can (optionally) manually add STRING functional scoring output tables to the results folder, and they will be combined with the output from SynEnrich. For this, STRING tables have to be formatted first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import format_string_table\n",
    "\n",
    "string_file1 = f\"{savepath}/syn.string.logFC.{project_name}.tsv\"\n",
    "string_file2 = f\"{savepath}/syn.string.neg_signed_logpval.{project_name}.tsv\"\n",
    "\n",
    "for string_file in [string_file1, string_file2]:\n",
    "\n",
    "    string = pd.read_csv(string_file, index_col=0, sep=\"\\t\")\n",
    "\n",
    "    for library in [\"GO\", \"KEGG\"]:\n",
    "        string_formatted = format_string_table(string, library)\n",
    "        display(string_formatted.head())\n",
    "        string_formatted.to_csv(string_file.replace(f\"{project_name}.tsv\", f\"{library}.{project_name}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ClusterProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "source(\"../../.Rprofile\")\n",
    ".libPaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i input_file\n",
    "library(clusterProfiler)\n",
    "library(org.Hs.eg.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "filepath <- paste0(\"../../\",input_file)\n",
    "\n",
    "metrics = c(\"neg_signed_logpval\",\"logFC\")\n",
    "\n",
    "df <- read.csv(filepath, row.names = 1)\n",
    "\n",
    "for (metric in metrics) {\n",
    "    # Check if the metric is in the columns\n",
    "    if (!(metric %in% colnames(df))) {\n",
    "            if (metric == \"neg_signed_logpval\") {\n",
    "                message(paste(\"Adding\", metric, \"to df\"))\n",
    "                df$neg_signed_logpval <- -sign(df$logFC) * log10(df$PValue)\n",
    "            } else {\n",
    "                stop(paste(\"Metric\", metric, \"not in columns!\"))\n",
    "            }\n",
    "        }\n",
    "}\n",
    "\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "run_clusterProfiler <- function(df, savepath, paramset,\n",
    "                                metric, cluster, overwrite=FALSE, \n",
    "                                organism.KEGG=\"hsa\",\n",
    "                                organism.GO = org.Hs.eg.db, seed=123) \n",
    "{\n",
    "  set.seed(seed)\n",
    "\n",
    "  outfile_go <- paste0(savepath,\"/cluster.gseGO.\",metric,\".\",paramset,\".csv\")\n",
    "  outfile_kegg <- paste0(savepath,\"/cluster.gseKEGG.\",metric,\".\",paramset,\".csv\")\n",
    "  print(outfile_go)\n",
    "  print(outfile_kegg)\n",
    "\n",
    "  if (file.exists(outfile_go) && file.exists(outfile_kegg) && !overwrite) {\n",
    "    print(\"Existing files not overwritte, skipping\")\n",
    "    return\n",
    "  }\n",
    "\n",
    "  start_time <- Sys.time()\n",
    "\n",
    "  geneList <- df[[metric]]\n",
    "  names(geneList) <- df$ENTREZID\n",
    "  geneList = sort(geneList, decreasing = TRUE)\n",
    "\n",
    "  if (!file.exists(outfile_go) || overwrite) {\n",
    "\n",
    "    ego3 <- gseGO(geneList     = geneList,\n",
    "                  OrgDb        = organism.GO,\n",
    "                  ont          = \"ALL\", ## CC MF BP\n",
    "                  minGSSize    = 10,\n",
    "                  maxGSSize    = 500,\n",
    "                  pvalueCutoff = 1,\n",
    "                  eps = 0,\n",
    "                  seed = TRUE,\n",
    "                  verbose = FALSE)\n",
    "    write.csv(ego3,outfile_go)\n",
    "  }\n",
    "\n",
    "  if (!file.exists(outfile_kegg) || overwrite) {\n",
    "\n",
    "    kegg <- gseKEGG(geneList     = geneList,\n",
    "                  organism        =  organism.KEGG,\n",
    "                  minGSSize    = 10,\n",
    "                  maxGSSize    = 500,\n",
    "                  pvalueCutoff = 1,\n",
    "                  eps = 0,\n",
    "                  seed = TRUE,\n",
    "                  verbose = FALSE)\n",
    "    write.csv(kegg,outfile_kegg)\n",
    "  }\n",
    "\n",
    "  end_time <- Sys.time()\n",
    "  print(end_time - start_time)\n",
    "}\n",
    "\n",
    "convert_df <- function(df, OrgDb=org.Hs.eg.db) {\n",
    "\n",
    "  if (\"ENTREZID\" %in% names(df)) return(df)\n",
    "  \n",
    "  df$ENSEMBL <- row.names(df)\n",
    "  # Convert to ENTREZ ID\n",
    "  # We will lose some genes here because not all IDs will be converted\n",
    "\n",
    "  ids<-bitr(row.names(df), fromType = \"ENSEMBL\", toType = \"ENTREZID\", OrgDb=OrgDb)\n",
    "  df <- merge(df, ids, by = \"ENSEMBL\", all.x = TRUE)\n",
    "  print(paste(\"Before\",nrow(df)))\n",
    "  df <- na.omit(df)\n",
    "  print(paste(\"After\",nrow(df)))\n",
    "  return(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "df <- convert_df(df, OrgDb=org.Hs.eg.db)\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i project_name\n",
    "savepath <- paste0(\"../../results/\",project_name)\n",
    "paramset <- \"test\"\n",
    "metric <- \"neg_signed_logpval\"\n",
    "df <- convert_df(df, OrgDb=org.Hs.eg.db)\n",
    "run_clusterProfiler(df, savepath, paramset,\n",
    "                                metric, overwrite=FALSE, \n",
    "                                organism.KEGG=\"hsa\",\n",
    "                                organism.GO = org.Hs.eg.db) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SynEnrich",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
