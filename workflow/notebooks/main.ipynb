{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import yaml\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "palette = sns.color_palette()\n",
    "pd.options.mode.copy_on_write = True\n",
    "scripts_dir = os.path.abspath(os.path.join(os.getcwd(), \"../scripts\"))\n",
    "sys.path.append(scripts_dir)\n",
    "workflows_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(workflows_dir)\n",
    "\n",
    "pretty_print = {\"string\": \"STRING\",\n",
    "      \"gseapy\": \"GSEApy\",\n",
    "      \"clusterProfiler\": \"ClusterProfiler\",\n",
    "      \"neg_signed_logpval\": \"signed logPValue\",\n",
    "      \"logFC\": \"logFC\",\n",
    "      \"s2n\":\"Signal-to-noise\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define params\n",
    "\n",
    "- `input_file`: Path (relative to project root) to a csv file containing a table with gene identifiers and ranking metric(s). Input files should be put in the `resources` folder.\n",
    "  \n",
    "- `project_name`: A string to tag output files. Results will be saved in `results/{project_name}/some_filename.{project_name}.csv`\n",
    "\n",
    "- `metrics`: A list of strings specifying columns in the input table that are used to rank the genes.\n",
    "\n",
    "- `libraries`: A list of libraries to be included. Currently supported: \"KEGG\", \"GO\", or path to .gmt file. If .gmt file is provided, `keytype_gmt` must be specified.\n",
    "\n",
    "- `tools`: A list of strings specifying the tools to be used. Currently supported : \"clusterProfiler\", \"gseapy\", \"string\". If results from [STRING](https://string-db.org/cgi/input?sessionId=b9myRH3ZDO2O&input_page_active_form=proteins_with_values) are to be used, the tsv files must be downloaded from the web tool and saved in the results folder (see \"Format STRING table\").\n",
    "  \n",
    "- `keytype`: String specifying the [type of gene identifier](https://www.bioconductor.org/help/course-materials/2014/useR2014/Integration.html) in the input file, e.g. \"ENSEMBLE\" or \"SYMBOL\".\n",
    "\n",
    "- `keytype_gmt`: (Optional) String specifying the type of gene identifier in the provided .gmt file (if .gmt file is provded in `libraries`).\n",
    "\n",
    "- `organismKEGG`: Currently supported: \"hsa\" for human and \"mmu\" for mouse.\n",
    "\n",
    "- `qval`: Q-value threshold to define significant terms. This value can be easily changed later on in downstream inspection of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### User-defined variables ####\n",
    "\n",
    "input_file = \"resources/testdata/BRCA.edgerqlf.lfc0.csv\"\n",
    "project_name = \"BRCA.QLF\"\n",
    "\n",
    "metrics = ['logFC', 'neg_signed_logpval', 's2n']\n",
    "libraries = [\"KEGG\",\"GO\"]\n",
    "tools = [\"clusterProfiler\",\"gseapy\"]#,\"string\"]\n",
    "\n",
    "keytype = \"ENSEMBL\"\n",
    "keytype_gmt = \"\"\n",
    "organismKEGG = \"hsa\"\n",
    "qval = 0.05\n",
    "fig_formats = [\"png\",\"pdf\"]\n",
    "go_sem_sim = True\n",
    "go_sem_sim_max_distance = 0.2\n",
    "\n",
    "# Table with normalized expression values\n",
    "input_file_expression = \"../../resources/testdata/BRCA.csv\"\n",
    "control_tag = \"N\"\n",
    "case_tag = \"T\"\n",
    "\n",
    "# Lollipop plots\n",
    "depth_cutoff_lollipop = 7\n",
    "x_val_lollipop = \"NegSignedlogFDR\" # or SignedDepth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create config.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration dictionary\n",
    "config_data = {\n",
    "    'input_file': input_file,\n",
    "    'project_name': project_name,\n",
    "    'metrics': metrics,\n",
    "    'keytype': keytype,\n",
    "    'keytype_gmt': keytype_gmt if \"keytype_gmt\" in globals() else \"\",\n",
    "    'organismKEGG': organismKEGG,\n",
    "    'libraries': libraries,\n",
    "    'tools': tools,\n",
    "    'qval': qval,\n",
    "    'save_summary_dict': True,\n",
    "    'make_figs': True,\n",
    "    'pretty_print': pretty_print,\n",
    "    'fig_formats': fig_formats,\n",
    "    'go_sem_sim': go_sem_sim,\n",
    "    'go_sem_sim_max_distance': go_sem_sim_max_distance,\n",
    "    'depth_cutoff_lollipop': depth_cutoff_lollipop,\n",
    "    'x_val_lollipop': x_val_lollipop,\n",
    "    'gseapy_kwargs': {}\n",
    "}\n",
    "\n",
    "# Write to config.yaml\n",
    "config_filename = \"../../config/config.yaml\"\n",
    "with open(config_filename, 'w') as file:\n",
    "    yaml.dump(config_data, file, default_flow_style=False)\n",
    "\n",
    "print(f\"Configuration file '{config_filename}' created successfully!\")\n",
    "\n",
    "savepath = f\"../../results/{project_name}/\"\n",
    "figpath = f\"../../results/{project_name}/figures/\"\n",
    "!mkdir -p $figpath\n",
    "\n",
    "lib_names = {os.path.splitext(os.path.basename(lib))[0]: lib for lib in libraries}\n",
    "max_depth = len(metrics)*len(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect/modify input\n",
    "\n",
    "This space can be used to calculate further ranking metrics that are missing in the input table. As an example, we read the output table from edgeR, calculate $-\\mathrm{sign}(\\log_2\\mathrm{FC})\\times\\log_{10}(p\\mathrm{-value})$, and add this as a new column to the table.\n",
    "\n",
    "**Careful:** Updating input files after jobs have been run will re-run the jobs the next time Snakemake is run. To prevent this, you can use `--touch` to update the timestamps of previously generated output files:\n",
    "\n",
    "`snakemake --touch --cores 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add negative signed log pval\n",
    "\n",
    "df = pd.read_csv(f\"../../{input_file}\", index_col=0)\n",
    "df[\"neg_signed_logpval\"] = -np.sign(df[\"logFC\"]) * np.log10(df[\"PValue\"])\n",
    "sig = df[df[\"FDR\"]<0.01]\n",
    "print(len(sig))\n",
    "\n",
    "# Optionally, if normalized count matrix provided, calculate signal-to-noise ratio\n",
    "\n",
    "def signal_to_noise(expr: pd.DataFrame, control: List[str], case: List[str]):\n",
    "    x1 = expr[control]\n",
    "    x2 = expr[case]\n",
    "    return (x2.mean(axis=1) - x1.mean(axis=1)) / (x1.std(axis=1) + x2.std(axis=1))\n",
    "\n",
    "if input_file_expression:\n",
    "    expr = pd.read_csv(input_file_expression, index_col=0)\n",
    "    control = [col for col in expr.columns if control_tag in col]\n",
    "    case = [col for col in expr.columns if case_tag in col]\n",
    "    s2n = signal_to_noise(expr, control, case)\n",
    "    df[\"s2n\"] = s2n.loc[df.index]\n",
    "\n",
    "\n",
    "display(df.sort_index().head())\n",
    "df.to_csv(f\"../../{input_file}\") # Uncomment to save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations\n",
    "\n",
    "Inspect correlations between the two different ranking metrics (e.g. logFC and signed pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank1 = \"logFC\"\n",
    "rank2 = \"s2n\"\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "### Pearson correlation\n",
    "\n",
    "correlation = df[rank1].corr(df[rank2], method='pearson')\n",
    "sns.regplot(x=df[rank1], y=df[\"neg_signed_logpval\"], ax=ax[0], scatter_kws={'alpha':0.1}, line_kws={\"color\":palette[3]})\n",
    "ax[0].set_title(f\"Pearson: {correlation:.2f}\")\n",
    "\n",
    "ax[0].set(xlabel=rank1)\n",
    "ax[0].set(ylabel=f\"{rank2}\")\n",
    "\n",
    "### Spearman rank correlation\n",
    "\n",
    "df['rank1'] = df[rank1].rank(method='average')\n",
    "df['rank2'] = df[rank2].rank(method='average')\n",
    "rank_correlation = df['rank1'].corr(df['rank2'], method='spearman')\n",
    "\n",
    "sns.regplot(x=df['rank1'] ,y=df['rank2'], ax=ax[1], scatter_kws={'alpha':0.01}, line_kws={\"color\":palette[3]})\n",
    "ax[1].set_title(f\"Spearman: {rank_correlation:.2f}\")\n",
    "fig.tight_layout()\n",
    "\n",
    "ax[1].set(xlabel=f\"{rank1} [Rank]\")\n",
    "ax[1].set(ylabel=f\"{rank2} [Rank]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Snakemake\n",
    "\n",
    "Run the following command in project root directory:\n",
    "\n",
    "`snakemake --use-conda --cores 1` (adjust number of cores as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# cores = 1\n",
    "# command = f\"snakemake -s ../Snakefile --configfile ../../config/config.yaml --use-conda --cores {cores}\"\n",
    "# subprocess.run(command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib\n",
    "from scripts.plots import npg_palette\n",
    "\n",
    "npg = npg_palette()\n",
    "output_files = glob.glob(f\"{savepath}/syn.*[tc]sv\")\n",
    "print(f\"Found {len(output_files)} output files:\\n\",*[o+\"\\n\" for o in output_files])\n",
    "\n",
    "summary_dict_file = f\"{savepath}/combined/syn.summary_dict.{project_name}.txt\"\n",
    "with open(summary_dict_file, \"rb\") as f:\n",
    "    summary_dict = pickle.load(f)\n",
    "\n",
    "print(\"summary_dict loaded\")\n",
    "summary_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case another qval threshold should be used\n",
    "# from scripts.combine_libs import create_summary_dict\n",
    "# qval = 0.01\n",
    "#summary_dict = create_summary_dict(f\"{savepath}/combined\",libraries,tools,metrics,project_name, qval=qval, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection depth\n",
    "\n",
    "We count the number of unique analysis configuations (methods, rankings) each significant term appears in. We designate this as the *intersection depth* of a term. A depth of $N$ means that the corresponding enrichment term is significant in exactly $N$ configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.plots import make_bar_plots\n",
    "\n",
    "make_bar_plots(summary_dict, figpath, project_name, lib_names, pretty_print=pretty_print, qval = qval, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Dict\n",
    "\n",
    "# def make_bar_plots2(summary_dict: Dict, \n",
    "#                     figpath: str,\n",
    "#                     project_name: str,\n",
    "#                     lib_names: Dict,\n",
    "#                     pretty_print: Dict,\n",
    "#                     qval: float = 0.05,\n",
    "#                     palette = npg_palette(),\n",
    "#                     max_depth: int = 0,\n",
    "#                     ext: str = \"pdf\"):\n",
    "\n",
    "#     sns.set_theme(font_scale=1.2)\n",
    "\n",
    "#     nlib = len(lib_names.keys())\n",
    "\n",
    "#     with sns.axes_style(\"whitegrid\"):\n",
    "#         fig, axes = plt.subplots(2, nlib, figsize=(nlib*5,10))\n",
    "#     axes = axes.flatten()\n",
    "\n",
    "#     ### Intersection depth\n",
    "\n",
    "#     for ax, lib in zip(axes[:nlib],lib_names.keys()):\n",
    "#         depth_df = summary_dict[lib][\"depth_df\"]\n",
    "#         if len(depth_df) < 1:\n",
    "#             print(f\"No terms found for {lib}\")\n",
    "#             continue\n",
    "#         h = sns.histplot(depth_df['Depth'], bins=depth_df['Depth'].max() - depth_df['Depth'].min() + 1, \n",
    "#                     discrete=True, ax=ax, alpha=1, color=palette[3])\n",
    "#         h.bar_label(h.containers[0])\n",
    "#         ax.set(title=\"Gene Ontology Terms (5% FDR)\", xlabel=\"Robustness\", ylabel=\"Terms\")\n",
    "#         xmax = max_depth if max_depth else depth_df['Depth'].max()\n",
    "#         ax.set_xticks(range(1, xmax+1))\n",
    "#         ax.set_xlim(0.25,xmax+0.75)\n",
    "#         ax.grid(axis='x')        \n",
    "        \n",
    "#     ### Number of terms\n",
    "\n",
    "#     for ax, lib in zip(axes[nlib:], lib_names.keys()):\n",
    "#         summary_df = summary_dict[lib][\"summary_df\"]\n",
    "#         qv = summary_df.drop([\"Combined\",\"nan\"], axis=1, level=0)\n",
    "#         qv = qv.xs(\"qvalue\", level=2, axis=1)\n",
    "#         qv = qv.replace(np.nan,1)\n",
    "#         qv = qv < qval\n",
    "\n",
    "#         qqv=qv.sum().reset_index()\n",
    "#         if pretty_print:\n",
    "#             qqv.replace({\"Tool\": pretty_print, \"Metric\": pretty_print}, inplace=True)\n",
    "#         qqv.index = qqv[\"Tool\"] + \"\\n\" + qqv[\"Metric\"]\n",
    "#         qqv = qqv.drop([\"Tool\",\"Metric\"], axis=1)\n",
    "#         qqv = qqv.sort_values(by=qqv.columns[0], ascending=False)\n",
    "\n",
    "#         if ax == axes[nlib]:\n",
    "#             hue_order = {qqv.index[i]: palette[i] for i in range(len(qqv))}\n",
    "\n",
    "#         qqv[\"hue\"] = qqv.index\n",
    "#         b = sns.barplot(data=qqv, x=qqv.index, y=qqv.iloc[:, 0], ax=ax, alpha=1, hue = 'hue', palette=palette, hue_order=hue_order)\n",
    "#         for i in b.containers:\n",
    "#             b.bar_label(i,)\n",
    "            \n",
    "#         ax.set_xticks(ax.get_xticks(), ax.get_xticklabels(), rotation=60, ha='right')\n",
    "#         ax.set(title=lib, ylabel=\"Terms\", xlabel=None)\n",
    "        \n",
    "#         # apply offset transform to all x ticklabels.\n",
    "#         offset = matplotlib.transforms.ScaledTranslation(12/72., 3/72., fig.dpi_scale_trans)\n",
    "#         for label in ax.xaxis.get_majorticklabels():\n",
    "#             label.set_transform(label.get_transform() + offset)\n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     fig.savefig(f\"{figpath}/bars.alt.{project_name}.{ext}\")\n",
    "\n",
    "\n",
    "# make_bar_plots2(summary_dict, figpath, project_name, lib_names, pretty_print=pretty_print, qval = qval, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Venn diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.plots import make_venn_plots\n",
    "\n",
    "make_venn_plots(summary_dict, figpath, project_name, lib_names, metrics, tools, pretty_print, qval = qval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UpSet plots\n",
    "\n",
    "Useful for visualizing set intersection with more than 3 sets. \n",
    "\n",
    "https://upsetplot.readthedocs.io/en/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.plots import make_upset_plots\n",
    "\n",
    "make_upset_plots(summary_dict, lib_names, figpath, project_name, pretty_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lollipop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.plots import make_lollipop_plots\n",
    "\n",
    "make_lollipop_plots(summary_dict,\n",
    "                        lib_names,\n",
    "                        figpath,\n",
    "                        project_name,\n",
    "                        top_terms = 30,\n",
    "                        qval = 0.05,\n",
    "                        depth_cutoff = 1, \n",
    "                        max_depth = max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-analysis\n",
    "\n",
    "Compare multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from scripts.plots import npg_palette\n",
    "\n",
    "npg = npg_palette()\n",
    "\n",
    "### PAPER\n",
    "\n",
    "project_names = [\"THCA.QLF\",\"BRCA.QLF\", \"KIRC.QLF\", \"LIHC.QLF\",\n",
    "                 \"Carmen.paired.QLF\", \n",
    "                 \"Chiara.QLF.KO_WT\", \"Chiara.QLF.SA_WT\", \"Chiara.QLF.SD_WT\",\n",
    "                 \"met.Exc7_DL.P90.p19rc\", \"met.Inh_Sncg.P14.p19rc\"]\n",
    "\n",
    "pretty_datanames = {\"BRCA.QLF\":\"TCGA.BRCA.N-T\",\n",
    "                    \"THCA.QLF\":\"TCGA.THCA.N-T\",\n",
    "                    \"KIRC.QLF\":\"TCGA.KIRC.N-T\",\n",
    "                    \"LIHC.QLF\":\"TCGA.LIHC.N-T\",\n",
    "                    \"met.Exc7_DL.P90.p19rc\": \"sn.Exc7.P90.WT-SA\",\n",
    "                    \"met.Inh_Sncg.P14.p19rc\": \"sn.Inh.Sncg.P14.WT-SA\",\n",
    "                    \"Chiara.QLF.KO_WT\":\"Ser1016.WT-KO\",\n",
    "                    \"Chiara.QLF.SA_WT\":\"Ser1016.WT-SA\",\n",
    "                    \"Chiara.QLF.SD_WT\":\"Ser1016.WT-SD\",\n",
    "                    \"Carmen.paired.QLF\":\"CHK2.WT-KO\"}\n",
    "\n",
    "meta_savepath = \"../../results/meta\"\n",
    "meta_project_name = \"meta\"\n",
    "\n",
    "### MET\n",
    "\n",
    "project_names = [\n",
    "    \"met.Astrocytes1.P14\",\n",
    "    \"met.Astrocytes2.P14\",\n",
    "    \"met.COPs.P14\",\n",
    "    \"met.Endothelial.P14\",\n",
    "    \"met.Exc1_SL.P14\",\n",
    "    \"met.Exc2_ML.P14\",\n",
    "    \"met.Exc3_ML.P14\",\n",
    "    \"met.Exc4_ML.P14\",  \n",
    "    \"met.Exc5_ML.P14\",  \n",
    "    \"met.Exc6_ML.P14\",\n",
    "    \"met.Exc7_DL.P14\",\n",
    "    \"met.Exc8_DL.P14\",\n",
    "    \"met.Exc9_DL.P14\",\n",
    "    \"met.Inh_Lamp5.P14\",\n",
    "    \"met.Inh_Meis2.P14\",\n",
    "    \"met.Inh_Pvalb.P14\",\n",
    "    \"met.Inh_Sst.P14\",\n",
    "    \"met.Inh_Vip.P14\",\n",
    "    \"met.MFO.P14\",\n",
    "    \"met.Microglia.P14\",\n",
    "    \"met.OPC.P14\",\n",
    "\n",
    "    \"met.Astrocytes1.P90\",\n",
    "    \"met.Endothelial.P90\",\n",
    "    \"met.Exc1_SL.P90\",\n",
    "    \"met.Exc2_ML.P90\",\n",
    "    \"met.Exc3_ML.P90\",\n",
    "    \"met.Exc6_ML.P90\",\n",
    "    \"met.Exc7_DL.P90\",\n",
    "    \"met.Exc8_DL.P90\",\n",
    "    \"met.Exc9_DL.P90\",\n",
    "    \"met.Inh_Lamp5.P90\",\n",
    "    \"met.Inh_Meis2.P14\"\n",
    "    \"met.Inh_Pvalb.P90\"\n",
    "    \"met.Inh_Sst.P90\",\n",
    "    \"met.Inh_Vip.P90\",\n",
    "    \"met.MFO.P90\",\n",
    "    \"met.Microglia.P90\",\n",
    "    \"met.OPC.P90\"\n",
    "]\n",
    "\n",
    "meta_savepath = \"../../results/meta.met\"\n",
    "meta_project_name = \"meta.met\"\n",
    "\n",
    "pretty_datanames = {p: p.split(\"met.\")[1] for p in project_names}\n",
    "\n",
    "meta_dict = dict()\n",
    "for project in project_names:\n",
    "    try:\n",
    "        with open(f\"../../results/{project}/combined/syn.summary_dict.{project}.txt\", \"rb\") as f:\n",
    "            meta_dict[project] = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Project not found: {project}\")\n",
    "\n",
    "npg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_summary_dict = dict()\n",
    "\n",
    "for lib in lib_names:\n",
    "    meta_summary_df = []\n",
    "    for project in meta_dict:\n",
    "        df = meta_dict[project][lib][\"summary_df\"]\n",
    "        df.index = df.index + \".\" + project # needed for venn\n",
    "        meta_summary_df.append(df)\n",
    "\n",
    "    meta_summary_df = pd.concat(meta_summary_df)\n",
    "    meta_summary_dict[lib] = dict()\n",
    "    meta_summary_dict[lib][\"summary_df\"] = meta_summary_df\n",
    "\n",
    "    meta_depth_df = []\n",
    "    for project in meta_dict:\n",
    "        depth_df_p = meta_dict[project][lib][\"depth_df\"]\n",
    "        depth_df_p[\"Project\"] = project\n",
    "        depth_df_p.replace({\"Project\":pretty_datanames}, inplace=True)\n",
    "        meta_depth_df.append(depth_df_p)\n",
    "\n",
    "    meta_depth_df = pd.concat(meta_depth_df)\n",
    "    meta_summary_dict[lib][\"depth_df\"] = meta_depth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "\n",
    "# palette = npg\n",
    "\n",
    "# sns.set(font_scale=1.2)\n",
    "# #sns.set_style(\"whitegrid\")\n",
    "# sns.set_style(\"ticks\")\n",
    "\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(10,10))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# ### Intersection depth\n",
    "\n",
    "# for ax, lib in zip(axes[:2],meta_depth_dict):\n",
    "#     sns.despine()\n",
    "#     depth_df = meta_depth_dict[lib]\n",
    "#     h = sns.histplot(depth_df['Depth'], bins=depth_df['Depth'].max() - depth_df['Depth'].min() + 1, \n",
    "#                 discrete=True, ax=ax, alpha=1, color=npg[3], label=\"Non-TCGA\")\n",
    "#     h.bar_label(h.containers[0])\n",
    "#     ax.set(title=lib, xlabel=\"Intersection Depth\", ylabel=\"Terms\")\n",
    "#     ax.set_xticks(range(depth_df['Depth'].min(), depth_df['Depth'].max() + 1))\n",
    "#     ax.grid(axis='x')\n",
    "\n",
    "#     ### plot TCGA only on top\n",
    "#     TCGA = depth_df[depth_df[\"Project\"].str.startswith(\"TCGA\")]\n",
    "#     sns.histplot(TCGA['Depth'], bins=depth_df['Depth'].max() - depth_df['Depth'].min() + 1, \n",
    "#                 discrete=True, ax=ax, alpha=1, color=npg[5], label=\"TCGA\")\n",
    "    \n",
    "#     ### label bars    \n",
    "#     nonTCGA = depth_df[~depth_df[\"Project\"].str.startswith(\"TCGA\")]\n",
    "#     nonTCGA_counts = nonTCGA['Depth'].value_counts().sort_index()\n",
    "#     TCGA_counts = TCGA['Depth'].value_counts().sort_index()\n",
    "#     for i in range(depth_df[\"Depth\"].max()):\n",
    "#         ax.text(s=TCGA_counts.iloc[i], x=i+1,y=TCGA_counts.iloc[i]/2,  va='center',ha='center')\n",
    "#         ax.text(s=nonTCGA_counts.iloc[i], x=i+1,y=TCGA_counts.iloc[i]+nonTCGA_counts.iloc[i]/2,  va='center',ha='center',color=\"white\")\n",
    "\n",
    "#     ax.legend(loc=\"best\")\n",
    "#     ax.grid(False)\n",
    "\n",
    "#     if ax == axes[0]:\n",
    "#         pass#ax.set_ylim(0,349)\n",
    "\n",
    "# ### Number of terms\n",
    "\n",
    "# for ax, lib in zip(axes[2:], meta_summary_dict):\n",
    "#     sns.despine()\n",
    "#     summary_df = meta_summary_dict[lib]\n",
    "#     qv = summary_df.drop([\"Combined\",\"nan\"], axis=1, level=0)\n",
    "#     qv = qv.xs(\"qvalue\", level=2, axis=1)\n",
    "#     qv = qv.replace(np.nan,1)\n",
    "#     qv = qv < qval\n",
    "\n",
    "#     qqv=qv.sum().reset_index()\n",
    "#     qqv.replace({\"Tool\": pretty_print, \"Metric\": pretty_print}, inplace=True)\n",
    "#     qqv.index = qqv[\"Tool\"] + \"\\n\" + qqv[\"Metric\"]\n",
    "#     qqv = qqv.drop([\"Tool\",\"Metric\"], axis=1)\n",
    "#     qqv = qqv.sort_values(by=qqv.columns[0], ascending=False)\n",
    "\n",
    "#     if ax == axes[2]:\n",
    "#         hue_order = {qqv.index[i]: npg[i] for i in range(len(qqv))}\n",
    "\n",
    "#     qqv[\"hue\"] = qqv.index\n",
    "#     b = sns.barplot(data=qqv, x=qqv.index, y=qqv.iloc[:, 0], ax=ax, alpha=1, hue = 'hue', palette=palette, hue_order=hue_order)\n",
    "#     for i in b.containers:\n",
    "#         b.bar_label(i,)\n",
    "#     ax.set_xticks(ax.get_xticks(), ax.get_xticklabels(), rotation=60, ha='right')\n",
    "#     ax.set(title=lib, ylabel=\"Terms\", xlabel=None)\n",
    "\n",
    "#     # apply offset transform to all x ticklabels.\n",
    "#     offset = matplotlib.transforms.ScaledTranslation(12/72., 3/72., fig.dpi_scale_trans)\n",
    "#     for label in ax.xaxis.get_majorticklabels():\n",
    "#         label.set_transform(label.get_transform() + offset)\n",
    "        \n",
    "# for i in range(len(axes)):\n",
    "#     axes[i].annotate(chr(ord('A')+i), xy=(-0.08, 1.04), xycoords=\"axes fraction\", weight=\"bold\", va='center',ha='center', fontsize=18)\n",
    "\n",
    "# fig.tight_layout()\n",
    "# fig.savefig(os.path.join(meta_savepath, \"bars.meta.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.plots import make_bar_plots\n",
    "\n",
    "make_bar_plots(summary_dict=meta_summary_dict,\n",
    "               figpath = meta_savepath,\n",
    "                    project_name =  meta_project_name,\n",
    "                    lib_names = lib_names,\n",
    "                    pretty_print = pretty_print,\n",
    "                    qval = 0.05,\n",
    "                    palette = npg_palette(),\n",
    "                    max_depth = max_depth,\n",
    "                    ext = \"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.plots import make_venn_plots\n",
    "\n",
    "make_venn_plots(summary_dict = meta_summary_dict, \n",
    "                    figpath = meta_savepath,\n",
    "                    project_name = meta_project_name,\n",
    "                    lib_names = lib_names,\n",
    "                    metrics = metrics,\n",
    "                    tools = tools,\n",
    "                    pretty_print = pretty_print,\n",
    "                    qval = 0.05,\n",
    "                    ext = \"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.plots import make_upset_plots\n",
    "\n",
    "make_upset_plots(summary_dict = meta_summary_dict, \n",
    "                    lib_names = lib_names,\n",
    "                    figpath = meta_savepath,\n",
    "                    project_name = meta_project_name,\n",
    "                    pretty_print = pretty_print,\n",
    "                    ext = \"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_style(\"ticks\")\n",
    "sns.despine()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12+len(project_names)//3, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "### Number of terms per dataset\n",
    "\n",
    "for ax, lib in zip(axes[:2],lib_names):\n",
    "    sns.despine()\n",
    "    depth_df = meta_summary_dict[lib][\"depth_df\"]\n",
    "    depth_df.replace({\"Project\":pretty_datanames}, inplace=True)\n",
    "\n",
    "    counts = depth_df.groupby([\"Project\"]).count()[\"Configurations\"].sort_values(ascending=False)\n",
    "\n",
    "    counts = pd.DataFrame(counts)\n",
    "\n",
    "    counts[\"hue\"] = counts.index\n",
    "    #counts.replace({\"hue\":pretty_datanames}, inplace=True)\n",
    "\n",
    "    if ax == axes[0]:\n",
    "        hue_order = {counts.iloc[i][\"hue\"]: npg[i%len(npg)] for i in range(len(counts))}\n",
    "        \n",
    "    b = sns.barplot(data=counts, y=\"Configurations\", x=\"hue\", ax=ax, hue=\"hue\", hue_order=hue_order, palette=npg[:len(project_names)])\n",
    "    ax.set(title=lib,xlabel=None,ylabel=\"Combined Terms\")\n",
    "\n",
    "    for i in b.containers:\n",
    "        b.bar_label(i,)\n",
    "\n",
    "    # if ax == axes[1]:\n",
    "    #     ax.set_ylim(0,2999)\n",
    "    \n",
    "    # if ax == axes[0]:\n",
    "    #     ax.set_ylim(0,199)\n",
    "\n",
    "    # mark depths with horzontal lines\n",
    "    g = depth_df.groupby([\"Project\"])[\"Depth\"].value_counts()\n",
    "    for j, p in enumerate(counts.index):\n",
    "        sum = 0\n",
    "        prev_sum = 0\n",
    "        maxdepth = g.index.get_level_values(\"Depth\").max()\n",
    "        for i in range(1,1+maxdepth):\n",
    "            try:\n",
    "                sum += g.loc[(p,i)]\n",
    "            except KeyError:\n",
    "                pass\n",
    "            if i < maxdepth:\n",
    "                ax.scatter(j, sum, marker=\"_\", color=\"black\", s=550, alpha=0.5)\n",
    "            if j == 0:\n",
    "                ax.text(s=f\"d{i}\",x=j,y=prev_sum + 0.5*(sum-prev_sum), ha=\"center\", va=\"center\",fontsize=10)\n",
    "            prev_sum = sum\n",
    "\n",
    "for ax, lib in zip(axes[2:], lib_names):\n",
    "    depth_df = meta_summary_dict[lib][\"depth_df\"]\n",
    "    #depth_df.replace({\"Project\":pretty_datanames}, inplace=True)\n",
    "    #sns.barplot(data=depth_df, x=\"Project\", y=\"Depth\", hue=\"Project\", errorbar=\"sd\", ax=ax, order=hue_order.keys(), hue_order=hue_order, palette=npg[:len(project_names)])\n",
    "    sns.boxplot(data=depth_df, x=\"Project\", y=\"Depth\", hue=\"Project\", ax=ax, order=hue_order.keys(), hue_order=hue_order, palette=npg[:len(project_names)])\n",
    "    ax.set(ylabel=\"Enrichment Depth\",title=lib)\n",
    "\n",
    "    if ax == axes[3]:\n",
    "        ax.set_ylim(axes[2].get_ylim())\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    axes[i].annotate(chr(ord('A')+i), xy=(-0.08, 1.04), xycoords=\"axes fraction\", weight=\"bold\", va='center',ha='center', fontsize=18)\n",
    "    axes[i].set_xticks(axes[i].get_xticks(), axes[i].get_xticklabels(), rotation=30, ha='right')\n",
    "    axes[i].set(xlabel=None)\n",
    "\n",
    "    # annotate KI\n",
    "    # axes[i].axvline(len(pretty_datanames)-4.5,0,axes[i].get_ylim()[1],ls=\"--\",color=\"black\",alpha=0.7)\n",
    "    #axes[i].annotate(\"KI\", xy=(0,0), xytext=(len(pretty_datanames)-3, 0.8*axes[i].get_ylim()[1] ), xycoords=\"data\",zorder=99)\n",
    "\n",
    "    # if i == 0:\n",
    "    #     axes[i].annotate(\"KI\", xy=(0,0), xytext=(0.78,0.8), xycoords=\"axes fraction\",zorder=99)\n",
    "    # elif i == 1:\n",
    "    #     axes[i].annotate(\"KI\", xy=(0,0), xytext=(0.78,0.735), xycoords=\"axes fraction\",zorder=99)\n",
    "    # elif i == 2:\n",
    "    #     axes[i].annotate(\"KI\", xy=(0,0), xytext=(0.78,0.84), xycoords=\"axes fraction\",zorder=99)\n",
    "    # else:\n",
    "    #     axes[i].annotate(\"KI\", xy=(0,0), xytext=(0.78,0.84), xycoords=\"axes fraction\",zorder=99)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{meta_savepath}/bars.data.meta.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golib = \"GO_STRING_mouse\"\n",
    "d = meta_summary_dict[golib][\"depth_df\"]\n",
    "d[\"n_genes\"] = d[\"Genes\"].str.split(\";\").apply(lambda x: len(x))\n",
    "d[\"logFDR\"] = -np.log10(d[\"Combined FDR\"])\n",
    "fig, ax = plt.subplots(2,3, figsize=(15,10))\n",
    "ax = ax.flatten()\n",
    "\n",
    "sns.violinplot(data=d, x=\"Direction\", y=\"Depth\", ax=ax[0])\n",
    "ax[0].set(xlabel=\"Direction\", ylabel=\"Robustness\")\n",
    "\n",
    "sns.violinplot(data=d, x=\"ONTOLOGY\", y=\"Depth\", ax=ax[1])\n",
    "ax[1].set(xlabel=\"Domain\", ylabel=\"Robustness\")\n",
    "\n",
    "sns.violinplot(data=d, x=\"Enrichr\", y=\"Depth\", ax=ax[2])\n",
    "ax[2].set(xlabel=\"Enrichr\", ylabel=\"Robustness\")\n",
    "\n",
    "sns.violinplot(data=d, x=\"Depth\", y=\"n_genes\", ax=ax[3])\n",
    "ax[3].set(xlabel=\"Robustness\", ylabel=\"# Genes in Term\")\n",
    "\n",
    "sns.violinplot(data=d, x=\"Depth\", y=\"logFDR\", ax=ax[4])\n",
    "ax[4].set(xlabel=\"Robustness\", ylabel=\"-log10 FDR\")\n",
    "\n",
    "sns.violinplot(data=d, x=\"Enrichr\", y=\"n_genes\", ax=ax[5])\n",
    "ax[5].set(xlabel=\"Enrichr\", ylabel=\"# Genes in Term\")\n",
    "\n",
    "fig.suptitle(golib)\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{meta_savepath}/violin.meta.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STRING\n",
    "\n",
    "### Format STRING table\n",
    "\n",
    "User can (optionally) manually add [STRING](https://string-db.org/cgi/input?sessionId=b9myRH3ZDO2O&input_page_active_form=proteins_with_values) functional scoring output tables to the results folder, and they will be combined with the output from SynEnrich. For this, STRING tables have to be formatted first:\n",
    "\n",
    "1) Download the .tsv file from the STRING web tool and save it in `results/{project_name}`.\n",
    "\n",
    "2) Rename the file to `syn.string.{metric}.{project_name}.tsv` where {metric} is to be replaced with the ranking metric (e.g. logFC) and {project_name} with the project name specified at the beginning of this notebook.\n",
    "\n",
    "3) Use the cell below to format the STRING table (which will split the file in separate KEGG and GO tables and rename some columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import format_string_table\n",
    "\n",
    "string_file1 = f\"{savepath}/syn.string.logFC.{project_name}.tsv\"\n",
    "string_file2 = f\"{savepath}/syn.string.neg_signed_logpval.{project_name}.tsv\"\n",
    "string_file3 = f\"{savepath}/syn.string.s2n.{project_name}.tsv\"\n",
    "\n",
    "string_files = [string_file1, string_file2, string_file3]\n",
    "#string_files = [string_file3]\n",
    "\n",
    "for string_file in string_files:\n",
    "\n",
    "    string = pd.read_csv(string_file, index_col=0, sep=\"\\t\")\n",
    "\n",
    "    for library in libraries:\n",
    "        lib = \"GO\" if library.startswith(\"GO\") else library\n",
    "        if library.endswith(\".gmt\"): library = library[:-4]\n",
    "        string_formatted = format_string_table(string, lib)\n",
    "        #display(string_formatted.head())\n",
    "        string_formatted.to_csv(string_file.replace(f\"{project_name}.tsv\", f\"{library}.{project_name}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare STRING upload\n",
    "\n",
    "The cell below can be used to split the input table into several files for each ranking metric, which is convenient for uploading to STRING.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../\"+input_file, index_col=0)\n",
    "p = \"../../\" + \"/\".join(input_file.split(\"/\")[:-1])\n",
    "name = input_file.split(\"/\")[-1]\n",
    "for metric in metrics:\n",
    "    print(len(df[metric]))\n",
    "    df[metric] = df[metric].dropna()\n",
    "    print(len(df))\n",
    "    df[metric].to_csv(os.path.join(p,f\"string.input.{metric}.\"+name), header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create STRING gmt file\n",
    "\n",
    "The cell below can be used to format a txt file with enrichment terms [downloaded from STRING](https://string-db.org/cgi/download?sessionId=b26FUyLIdNfn) into a `.gmt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import create_string_gmt\n",
    "\n",
    "#infile = \"../../resources/Ontologies/9606.protein.enrichment.terms.v12.0.tsv\" #human \n",
    "infile = \"../../resources/Ontologies/10090.protein.enrichment.terms.v12.0.txt\" #mouse\n",
    "\n",
    "orgid = os.path.basename(infile).split(\".\")[0]\n",
    "orgid_dict = {\"9606\": \"human\", \"10090\": \"mouse\"}\n",
    "species = orgid_dict[orgid]\n",
    "print(orgid, species)\n",
    "\n",
    "outfile = f'../../resources/Ontologies/GO_STRING_{species}.gmt'\n",
    "\n",
    "create_string_gmt(infile, outfile, orgid, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scripts.plots\n",
    "# import importlib\n",
    "# importlib.reload(scripts.plots)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SynEnrich",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
