# Snakefile


# Config file
configfile: "config/config.yaml"


input_file = config["input_file"]
project_name = config["project_name"]
metrics = config["metrics"]

libraries = config["libraries"]  # either "GO", "KEGG", or path to gmt file
lib_names = {os.path.splitext(os.path.basename(l))[0]: l for l in libraries}
for l in lib_names:
    assert "." not in l

tools = config["tools"]
save_summary_dict = config["save_summary_dict"]
make_figs = config["make_figs"]
qval = config["qval"]
fdr = config["FDR"]
savepath = os.path.join("results", project_name)
cachepath = os.path.join(savepath, ".cache")
string_api_key = config["string_api_key"]

if string_api_key in ["", None]:
    string_api_key = "_"  # avoid empty arg when calling from CLI

fig_formats = config["fig_formats"]
if not isinstance(fig_formats, list):
    fig_formats = [fig_formats]

go_sem_sim = config["go_sem_sim"]

# Gene conversion
gene_converter = f"results/{project_name}/gene_converter.csv"

# ClusterProfiler params
keytype = config["keytype"]
keytype_gmt = config["keytype_gmt"]
organismKEGG = config["organismKEGG"]

# Define result paths based on project name
gsea_output = (
    f"results/{project_name}/syn.{{tool}}.{{metric}}.{{library}}.{project_name}.csv"
)
combined_configurations_output = (
    f"results/{project_name}/combined/syn.combined.{{library}}.{project_name}.csv"
)
depth_output = (
    f"results/{project_name}/combined/syn.depth.{{library}}.{project_name}.csv"
)
summary_dict_output = (
    f"results/{project_name}/combined/syn.summary_dict.{project_name}.txt"
)

all_intermediate_outputs = expand(
    gsea_output, metric=metrics, library=lib_names.keys(), tool=tools
)  # [t for t in tools if t != "string"])
final_configurations_outputs = expand(
    combined_configurations_output, library=lib_names.keys()
)
final_depth_outputs = expand(depth_output, library=lib_names.keys())

if make_figs:
    lollipop_plots = (
        f"results/{project_name}/figures/lollipop.{{library}}.{project_name}.{{ext}}"
    )
    bar_plots = f"results/{project_name}/figures/bars.{project_name}.{{ext}}"
    upset_plots = (
        f"results/{project_name}/figures/upset.{{library}}.{project_name}.{{ext}}"
    )
    venn_metric = (
        f"results/{project_name}/figures/venn.metriccomp.{project_name}.{{ext}}"
    )
    venn_method = (
        f"results/{project_name}/figures/venn.methodcomp.{project_name}.{{ext}}"
    )

    all_bars = expand(bar_plots, ext=fig_formats)
    all_vennmetric = expand(venn_metric, ext=fig_formats)
    all_vennmethod = expand(venn_method, ext=fig_formats)
    all_lollipop = expand(lollipop_plots, library=lib_names.keys(), ext=fig_formats)
    all_upset = expand(upset_plots, library=lib_names.keys(), ext=fig_formats)
    all_figs = all_upset + all_lollipop + all_bars + all_vennmetric + all_vennmethod
else:
    all_figs = []

if go_sem_sim:
    depth_output_GO = (
        f"results/{project_name}/combined/syn.depth.{{library}}.{project_name}.csv"
    )
    go_libraries = [lib for lib in lib_names.keys() if lib.startswith("GO")]
    depth_output_GO_files = expand(depth_output_GO, library=go_libraries)
    subontologies = ["BP", "CC", "MF"]
    semsim_out = expand(
        f"{cachepath}/sim_matrix_{{subontology}}.csv", subontology=subontologies
    )
    go_heatmaps = os.path.join(
        "results",
        project_name,
        "figures",
        f"go.heat.{{subont}}.{{lib}}.{project_name}.png",
    )
    all_go_heatmaps = expand(go_heatmaps, subont=subontologies, lib=go_libraries)
else:
    semsim_out = []
    all_go_heatmaps = []


# Define the final target files based on the method selected
rule all:
    input:
        summary_dict_output,
        final_configurations_outputs,
        all_intermediate_outputs,
        final_depth_outputs,
        all_figs,
        semsim_out,
        all_go_heatmaps,


# Rule for creating gene name converter table
rule run_geneconverter:
    input:
        input_file,
    output:
        gene_converter,
    conda:
        "envs/environment.clusterprofiler.yaml"
    shell:
        """
        Rscript workflow/scripts/run_geneconverter.R {input} {keytype} {organismKEGG} {gene_converter}
        """

# String runs with a fixed set of libraries
# Retruns one df with all libraries; we will split manually into GO, KEGG
rule run_string:
    input:
        infile=input_file,
        g=gene_converter,
    output:
        f"results/{project_name}/syn.string.{{metric}}.GO.{project_name}.csv" if ( "string" in tools and "GO" in lib_names.keys() ) else [],
        f"results/{project_name}/syn.string.{{metric}}.KEGG.{project_name}.csv" if ( "string" in tools and "KEGG" in lib_names.keys() ) else [],
    conda:
        "envs/environment.yaml"
    params:
        outfile_no_lib = lambda wildcards: f"results/{project_name}/syn.string.{wildcards.metric}._PLACEHOLDER_.{project_name}.csv",
    shell:
        """
        python workflow/scripts/run_string.py {input.infile} {string_api_key} {keytype} {organismKEGG} {gene_converter} {wildcards.metric} {params.outfile_no_lib} {fdr}
        """


rule run_clusterprofiler:
    input:
        infile=input_file,
        g=gene_converter,
    output:
        outfile=(
            f"results/{project_name}/syn.clusterProfiler.{{metric}}.{{library}}.{project_name}.csv"
            if "clusterProfiler" in tools
            else ""
        ),
    conda:
        "envs/environment.clusterprofiler.yaml"
    params:
        library_name=lambda wildcards: lib_names[wildcards.library],
    shell:
        """
        echo Running ClusterProfiler with: {wildcards}
        Rscript workflow/scripts/run_clusterprofiler.R {input.infile} {organismKEGG} {gene_converter} {wildcards.metric} {params.library_name} {output.outfile} {keytype} {keytype_gmt}
        """


rule run_gseapy:
    input:
        infile=input_file,
        g=gene_converter,
    output:
        outfile=(
            f"results/{project_name}/syn.gseapy.{{metric}}.{{library}}.{project_name}.csv"
            if "gseapy" in tools
            else ""
        ),
    params:
        library_name=lambda wildcards: lib_names[wildcards.library],
    conda:
        "envs/environment.yaml"
    shell:
        """
        echo Running GSEApy with: {wildcards}

        python workflow/scripts/run_gseapy.py {input.infile} {keytype} {organismKEGG} {gene_converter} {wildcards.metric} {params.library_name} {output.outfile}
        """


# Rule to combine results from different configurations (metrics, tools)
rule combine_results_from_different_configurations:
    input:
        all_intermediate_outputs,
        gene_converter,
    output:
        final_configurations_outputs,
    conda:
        "envs/environment.yaml"
    shell:
        """
        python workflow/scripts/combine_results.py {savepath} {final_configurations_outputs}
        """


rule combine_results_from_different_libraries:
    input:
        final_configurations_outputs,
    output:
        summary_dict_output,
        final_depth_outputs,
    conda:
        "envs/environment.yaml"
    shell:
        """
        python workflow/scripts/combine_libs.py
        """


if go_sem_sim:

    rule get_go_sem_sim_matrices:
        input:
            depth_files=depth_output_GO_files,
        output:
            outfile=semsim_out,
        conda:
            "envs/environment.clusterprofiler.yaml"
        shell:
            """
            Rscript workflow/scripts/gosemsim.R {input.depth_files} {organismKEGG} {cachepath} {qval}
            """


rule append_GO_clusters_to_depth_df:
    input:
        semsim_out,
    output:
        all_go_heatmaps,
    conda:
        "envs/environment.yaml"
    shell:
        """
        python3 workflow/scripts/clustering.py # note: this updates depth_df
        """


# TO DO: make rule finalize_combined_outputs that saves depth_df, summary_dict after GOSemSim; for now use snakemake --touch as workaround


rule make_plots:
    input:
        all_go_heatmaps,
        summary_dict_output,
    output:
        all_figs,
    conda:
        "envs/environment.yaml"
    shell:
        """
        python workflow/scripts/plots.py
        """
